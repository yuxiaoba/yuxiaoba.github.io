<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.4.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Guangba Yu" />

  
  
  
    
  
  <meta name="description" content="将神经网络扩展到数千亿个参数，使得GPT-4等取得了巨大的突破，但训练和推理这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。它只用几行代码就能实现大规模分布式训练和推理的并行自动化。" />

  
  <link rel="alternate" hreflang="en-us" href="https://yuxiaoba.github.io/post/alpa/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.2a85acfde01ecde91ff15c66a13984b7.css" />

  



  


  


  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://yuxiaoba.github.io/post/alpa/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Welcome to Guangba&#39;s HomePage" />
  <meta property="og:url" content="https://yuxiaoba.github.io/post/alpa/" />
  <meta property="og:title" content="ChatGPT 后面的分布式 AI 框架：Alpa | Welcome to Guangba&#39;s HomePage" />
  <meta property="og:description" content="将神经网络扩展到数千亿个参数，使得GPT-4等取得了巨大的突破，但训练和推理这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。它只用几行代码就能实现大规模分布式训练和推理的并行自动化。" /><meta property="og:image" content="https://yuxiaoba.github.io/post/alpa/featured.jpeg" />
    <meta property="twitter:image" content="https://yuxiaoba.github.io/post/alpa/featured.jpeg" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2023-06-05T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2023-06-05T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yuxiaoba.github.io/post/alpa/"
  },
  "headline": "ChatGPT 后面的分布式 AI 框架：Alpa",
  
  "image": [
    "https://yuxiaoba.github.io/post/alpa/featured.jpeg"
  ],
  
  "datePublished": "2023-06-05T00:00:00Z",
  "dateModified": "2023-06-05T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Guangba Yu"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Welcome to Guangba's HomePage",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yuxiaoba.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "将神经网络扩展到数千亿个参数，使得GPT-4等取得了巨大的突破，但训练和推理这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。它只用几行代码就能实现大规模分布式训练和推理的并行自动化。"
}
</script>

  

  

  

  





  <title>ChatGPT 后面的分布式 AI 框架：Alpa | Welcome to Guangba&#39;s HomePage</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="1deccd77b4d399bc141a629b858afe10" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ced4c4e0190cf57ce42494e355f2bdf6.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Welcome to Guangba&#39;s HomePage</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Welcome to Guangba&#39;s HomePage</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Blogs</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  





















  
  


<div class="article-container pt-3">
  <h1>ChatGPT 后面的分布式 AI 框架：Alpa</h1>

  
  <p class="page-subtitle">将神经网络扩展到数千亿个参数，使得GPT-4等取得了巨大的突破，但训练和推理这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。它只用几行代码就能实现大规模分布式训练和推理的并行自动化。</p>
  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Guangba Yu</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Jun 5, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    2 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/weekly-paper/">Weekly Paper</a></span>
  

</div>

  





</div>


<div class="article-header container featured-image-wrapper mt-4 mb-4" style="max-width: 1200px; max-height: 800px;">
  <div style="position: relative">
    <img src="/post/alpa/featured_hu3d03a01dcc18bc5be0e67db3d8d209a6_625910_1200x2500_fit_q75_h2_lanczos.webp" width="1200" height="800" alt="" class="featured-image">
    <span class="article-header-caption">Image credit: <a href="https://unsplash.com/photos/CpkOjOcXdUY"><strong>Unsplash</strong></a></span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>随着以 ChatGPT 为代表的大模型（LLM）技术的迅速发展，越来越多的企业和研究团队将目光聚焦于如何将大模型技术应用于自己的行业中，各种各样针对性的 Prompt 方法被提出来提高大模型技术在特定领域的适用性，以提高大模型技术的可靠性。除了提高 LLM 技术的适用性之外，我们还需要一个高性能且易于使用的机器学习基础设施来支撑 LLM 的训练和推理。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./model.gif" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>现代 LLM 的参数大小为数千亿，例如， OPT-175B 模型需要 350GB 的 GPU 内存来容纳模型参数，这已经超过了单个设备或主机的 GPU 内存，而即使是当前最先进的 NVIDIA A100 和 H100 GPU 显卡也仅只有 40GB / 80GB GPU 内存。因此，为了能够高效地运行 LLM 的训练和推理任务，工程师需要对模型进行划分，然后将子模型调度到能够满足计算内存需求的 GPU 主机上进行并行计算。</p>
<p>也就是说，对 LLM 的划分和编排调度成为了 LLM 的训练和推理的关键。下图展示了 NIVIDA 推荐的 LLM 训练和推理任务计算的技术栈。自顶向下来看，在开发人员对模型进行定义后，我们可以用 Alpa 对模型进行自动化的并行划分，然后基于 Ray 编排调度子任务，最后再由 GPU 显卡运行每个子任务。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./llm-stack.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>今天我们先来分享由 UC Berkeley 提出的 Alpa 框架，等夏至我们将继续分享 另外一个 Ray 的框架。Alpa 的原型是来自于 2022 年 UC Berkeley Rise Lab 团队发表在 CCF A 类的操作系统顶级会议 OSDI 上的论文 Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning。</p>
<h3 id="centerfont-colorffa5002022_osdi_alpa-automating-inter--and-intra-operator-parallelism-for-distributed-deep-learningfontcenter"><center><font color=#FFA500>2022_OSDI_Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning</font></center></h3>
<h4 id="论文背景"><strong>论文背景</strong></h4>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa1.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>在训练大模型的时候，我们通常会遇到两个与 “大” 相关的问题：一是输入的数据集非常大，二是模型非常大。</p>
<p>对于输入的数据集非常大的问题，我们可以通过对数据的并行处理，将输入的数据划分成多个数据集，然后在每个机器上单独进行训练。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa2.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>但如果输入的模型非常大呢？ 例如单个 GPU 最大内存是  32 GB，而模型需要  350 GB  进行存储，这个时候单个  GPU  是无法满足训练的需求的。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa3.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>这个时候问题就变成了如何对 Computational graph 进行划分和编排调度，让一个大模型的子任务能够并行地运行在有限内存的  GPU  设备上，最后再对子任务的结果进行组合获得最终的结果。</p>
<h4 id="论文动机"><strong>论文动机</strong></h4>
<p>对给定一个 computational graph 和对应的  GPU  设备，</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa4.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>典型的 computational graph 划分方式有 2 种：</p>
<ol>
<li>Inter-operator Parallelism：算子（operator）间并行</li>
</ol>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa5.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<ol start="2">
<li>Intra-operator Parallelism：算子（operator）内并行</li>
</ol>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa6.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>这两种并行方式各有优缺点，Inter-operator Parallelism 的方式可能会因为算子之间的等待导致更多的空闲设备，而 Intra-operator Parallelism 则会因为算子内部的数据分发导致更多的数据传输成本。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa7.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>为了克服以上两种并行方式的缺陷，我们可以很直观地想到可以将 Intra-op erator and Inter-operator Parallelism 组合起来，实现在最少的数据传输成本的条件下利用到更多的设备，从而尽快地训练完模型，这就是本文最核心的动机。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa8.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<h4 id="论文方法"><strong>论文方法</strong></h4>
<p>基于将 Intra-operator and Inter-operator Parallelism 组合起来加速模型训练的动机，论文提出了一个自动为大型 Deep Learning 模型找到并执行最佳的 Intra-operator and Inter-operator Parallelism 的编译器：Alpa。</p>
<p>Alpa 以 computational graph 和  device cluster 作为输入，输出并行方案。下图展示了它的整体架构，自上而下可分为 Inter-operator Parallelism 负责解决如何划分 Stage ，Stage 间如何流水线并行。Intra-operator Parallelism 负责解决如何划分 Stage 中的算子内部然后并行运行到不同的设备上。最后  Runtime Orchestration 进行编译优化。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa9.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<ol>
<li>Inter-operator Parallelism</li>
</ol>
<p>在 Inter-operator Parallelism 划分阶段，Alpa 首先将 Computational graph 划分成  Stage</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa10.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa11.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>然后 Alpa 以最小化 Pipeline 的运行延迟作为目标将 Stage 流水线化分配到多个设备上并行计算</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa12.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>对这个优化问题，Alpa 通过动态规划解决，具体的建模过程比较复杂，建议直接参考原论文</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa13.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<ol start="2">
<li>Intra-operator Parallelism</li>
</ol>
<p>在 Intra-operator Parallelism 划分阶段，Alpa 将每个 stage 中的 operator 进行进一步的划分。对于一个 operator，可以按 tensor 的行划分，也可以按  tensor 的列划分。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa14.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>在  Intra-operator Parallelism 阶段，会由于不同算子之间按行或者按列划分导致额外的  Communication cost,  如将算子按列划分在  GPU0-3  并行计算完后，需要将结果发送到 GPU0 进行汇总。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa15.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>此外还包括 Re-partition Communication Cost， 如从按行划分转换为按列划分，有  All-Gather 的开销。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa16.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>其他的开销建议可以参考旷视研究院周亦庄博士 《利用MegEngine的分布式通信算子实现复杂的并行训练》的  PPT，这里不再详细分享。</p>
<p>因此，在 Intra-operator Parallelism 除了考虑计算的开销外，还需考虑 communication cost 的开销，最后 Intra-operator Parallelism  的优化目标为最小化 computation  和 communication cost ， 然后 Alpa 用整数线性规划来解决此优化问题</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa17.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>最后将 Inter-operator 和  Intra-operator Parallelism 组合，即获得了 Alpa 最核心的分层优化方案</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa18.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<ol start="3">
<li>Runtime Orchestration</li>
</ol>
<p>在编译阶段，Alpa 采用 MPMD 风格的运行时，为每个设备网格生成不同的静态执行指令序列</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa19.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<h4 id="论文结果"><strong>论文结果</strong></h4>
<p>Alpa 基于Jax、HLO、RAY 实现完整的框架并开源到 <a href="https://github.com/alpa-projects/alpa" target="_blank" rel="noopener">https://github.com/alpa-projects/alpa</a></p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa20.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>Alpa 在使用时只需要在函数前加一句  @alpa.parallelize 即可</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa21.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>论文首先与之前的工作对比了不同调优方式的吞吐量，可以发现 Alpa 可以与最优的手动调整获得相似的结果，而且通用性更高</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa22.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>论文然后做了 Inter-Operator 和 Intra-Operator 的消融实验，整合了 Inter-Operator 和 Intra-Operator 的 Alpa 能够获得更高的吞吐</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="./alpa23.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>将神经网络扩展到数千亿个参数，使得GPT-3等取得了巨大的突破，但训练和服务这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。 它只用几行代码就能实现大规模分布式训练和推理的并行自动化。</p>
<p>Alpa 是一篇工作量非常大的论文，在上文中，我们只是简单的介绍了  Alpa 的核心思想，原文的内容远比我们介绍的复杂，同时论文的工程量也是相当的大，绝对是一篇  OSDI  级别的优秀论文。这就是国际上顶尖的研究团队。</p>
<p>Alpa 开源一年目前在Github 上已经有超过 2.5K 的Star，背靠   UC Berkeley Rise Lab 和  Ray ，我们有理由相信它还会有更好的发展，让我们一起期待它的未来吧～</p>
<blockquote>
<p>论文链接：<a href="https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf" target="_blank" rel="noopener">https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf</a>
代码链接：<a href="https://github.com/alpa-projects/alpa" target="_blank" rel="noopener">https://github.com/alpa-projects/alpa</a></p>
</blockquote>
<p>CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 <a href="https://github.com/IntelligentDDS/awesome-papers" target="_blank" rel="noopener">https://github.com/IntelligentDDS/awesome-papers</a></p>

    </div>

    




<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/gpt/">GPT</a>
  
  <a class="badge badge-light" href="/tag/ai/">AI</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://yuxiaoba.github.io/post/alpa/&amp;text=ChatGPT%20%e5%90%8e%e9%9d%a2%e7%9a%84%e5%88%86%e5%b8%83%e5%bc%8f%20AI%20%e6%a1%86%e6%9e%b6%ef%bc%9aAlpa" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://yuxiaoba.github.io/post/alpa/&amp;t=ChatGPT%20%e5%90%8e%e9%9d%a2%e7%9a%84%e5%88%86%e5%b8%83%e5%bc%8f%20AI%20%e6%a1%86%e6%9e%b6%ef%bc%9aAlpa" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=ChatGPT%20%e5%90%8e%e9%9d%a2%e7%9a%84%e5%88%86%e5%b8%83%e5%bc%8f%20AI%20%e6%a1%86%e6%9e%b6%ef%bc%9aAlpa&amp;body=https://yuxiaoba.github.io/post/alpa/" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://yuxiaoba.github.io/post/alpa/&amp;title=ChatGPT%20%e5%90%8e%e9%9d%a2%e7%9a%84%e5%88%86%e5%b8%83%e5%bc%8f%20AI%20%e6%a1%86%e6%9e%b6%ef%bc%9aAlpa" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=ChatGPT%20%e5%90%8e%e9%9d%a2%e7%9a%84%e5%88%86%e5%b8%83%e5%bc%8f%20AI%20%e6%a1%86%e6%9e%b6%ef%bc%9aAlpa%20https://yuxiaoba.github.io/post/alpa/" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://yuxiaoba.github.io/post/alpa/&amp;title=ChatGPT%20%e5%90%8e%e9%9d%a2%e7%9a%84%e5%88%86%e5%b8%83%e5%bc%8f%20AI%20%e6%a1%86%e6%9e%b6%ef%bc%9aAlpa" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://yuxiaoba.github.io"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu41bfb6d5380261963dae0a31a5eb6881_4674389_270x270_fill_q75_lanczos_center.jpg" alt="Guangba Yu"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://yuxiaoba.github.io">Guangba Yu</a></h5>
      <h6 class="card-subtitle">Ph.D. Candidate Focus on Cloud Native</h6>
      <p class="card-text">My research interests include cloud computing, microservices, Serverless, AIOps</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:yugb5@mail2.sysu.edu.cn" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?hl=en&amp;user=wXY0D6YAAAAJ" target="_blank" rel="noopener">
        <i class="fas fa-graduation-cap"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/yuxiaoba" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/guangba-yu-07b216192/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/uploads/resume.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  

  

  
  






  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js"></script>

    
    
    
      
      
        <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js" integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
        
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js" crossorigin="anonymous"></script>
        
      

    

    
    
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":true}</script>

    
    
      <script src="/js/wowchemy-headroom.79343bd00de25e04f03b6af2819f8643.js" type="module"></script>
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.f41ee09ba84b78e6bdd68fadc655c33f.js"></script>

    
    
    
    
    
    
      
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      <script src="/js/wowchemy-publication.ee00aa4e09ee62617fe2dc15bfcb3f7b.js" type="module"></script>






</body>
</html>
