<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPT | Welcome to Guangba&#39;s HomePage</title>
    <link>https://yuxiaoba.github.io/tag/gpt/</link>
      <atom:link href="https://yuxiaoba.github.io/tag/gpt/index.xml" rel="self" type="application/rss+xml" />
    <description>GPT</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 21 Jun 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yuxiaoba.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>GPT</title>
      <link>https://yuxiaoba.github.io/tag/gpt/</link>
    </image>
    
    <item>
      <title>Chatgpt 后面的分布式 AI 框架：Ray</title>
      <link>https://yuxiaoba.github.io/post/ray/</link>
      <pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://yuxiaoba.github.io/post/ray/</guid>
      <description>&lt;p&gt;在上一次的推送 &lt;a href=&#34;https://yuxiaoba.github.io/post/alpa/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChatGPT 后面的分布式 AI 框架：Alpa&lt;/a&gt; 中，我们介绍了随着LLM 的发展，LLM 模型的参数已经超过了单个设备的 GPU 内存，为了能够高效地运行 LLM 的训练和推理任务，工程师可以使用 Alpa 对模型进行划分，然后将子任务调度到能够满足计算内存需求的 GPU 设备上进行计算。&lt;/p&gt;
&lt;p&gt;那对模型进行划分以后，由什么框架来进行调度呢？与 Spark 和 Alpa 一母同胞，同样出自 UC Berkeley RiseLab 的 Ray 是当前一个热门的选择。Ray 是 2017 年 RiseLab 开源的通用的分布式调度框架，目前在  Github 上已经超过  2 W Star, 蚂蚁金服、OpenAI 等公司都使用它来调度机器学习任务。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./llm-stack.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;今天我们分享的论文就是 Ray 的论文原型，2018  年 UC Berkeley Rise Lab 团队发表在 CCF A 类的操作系统顶级会议 OSDI 上的论文：Ray: A Distributed Framework for Emerging AI Applications。值得注意的是，论文是  2018  年的，经过几年的迭代，当前的最新的  Ray 版本与论文的原型存在部分差异，但核心思想是不变的。&lt;/p&gt;
&lt;h3 id=&#34;centerfont-colorffa5002018_osdi_ray-a-distributed-framework-for-emerging-ai-applicationsfontcenter&#34;&gt;&lt;center&gt;&lt;font color=#FFA500&gt;2018_OSDI_Ray: A Distributed Framework for Emerging AI Applications&lt;/font&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h4 id=&#34;font-colorffa500论文背景-fontcenter&#34;&gt;&lt;font color=#FFA500&gt;&lt;strong&gt;论文背景&lt;/strong&gt; &lt;/font&gt;&lt;/center&gt;&lt;/h4&gt;
&lt;p&gt;现代 AI 应用，如强化学习，它已经不是由一种机器学习任务组成，而是会包含多种机器学习任务，比如 Data Processing、Training、Serving 和Simulation 等。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray1.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;不同类型的任务对计算模型、状态和时延的需求不同，AI 工程师可能需要基于不同的框架去设计和执行任务，比如在 Training 时使用TensorFlow 框架, 在Simulation 时使用  MPI 框架。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在这种情况下，AI 工程师不仅需要熟悉众多的框架，而且框架之间进行信息传递和交互也并非易事。 Ray 基于此痛点，提出了一个通用的机器学习任务调度框架，它能够适应和调度多种机器学习任务。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;font-colorffa500ray-框架-fontcenter&#34;&gt;&lt;font color=#FFA500&gt;&lt;strong&gt;Ray 框架&lt;/strong&gt;* &lt;/font&gt;&lt;/center&gt;&lt;/h4&gt;
&lt;p&gt;Ray 采取一种新的可横向扩展的分布式结构。Ray 的结构由两部分组成：Application Layer 和 System Layer。Application Layer 实现 API 和计算模型，执行分布式计算任务。System Layer 负责任务调度和数据管理，来满足表现性能和容错的要求。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray4.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Application Layer&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ray的 Application Layer 使用传统的 Driver-Worker 模式进行组织。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Driver：运行用户程序的进程&lt;/li&gt;
&lt;li&gt;Worker：执行指定的 stateless task&lt;/li&gt;
&lt;li&gt;Actor：执行指定的 stateful actor&lt;/li&gt;
&lt;li&gt;Local Scheduler：本地调度器，两级调度策略的第一级&lt;/li&gt;
&lt;li&gt;Object store：本地存储器，用于存储task输入输出结果。它是一个基于内存的对象存储，同节点的 worker 可以通过 shared mem 机制来获取数据&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;System  Layer&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Global Control Store (GSC) 维护整个系统的状态，他的核心是 KV 存储和基于 KV 存储的订阅发布机制。系统所有的控制状态都存储在 GSC 中，这样系统其他组件可以是无状态的。这不仅简化了对容错的支持（出现错误时，组件可以从 GSC 中读取最近状态并重新启动），也使得其他组件可以横向扩展&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Global Scheduler: 全局调度器，两级调度策略的第二级&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bottom-Up Distributed Scheduler:  如下图所示 Ray 调度时，首先 Driver 会提交 task 到 Local Scheduler，Local Scheduler 将 task 调度给 Local Worker，将完成不了的 task 提交到 Global Scheduler， Global Scheduler 会根据每个节点的资源和预期等待时间，决策任务的调度去向。预期的调度时间可以根据任务在队列中的时间，任务的网络IO耗时来决定。这些信息可以根据心跳机制来获取。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray5.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Ray Shedule Example&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示了由 Driver 调用 add.remote(a，b) 触发的逐步操作，其中 a 和 b 分别存储在节点 N1 和 N2 上。
N1 的 Driver 将 add(a，b)提交给 Local Scheduler&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. Local Scheduler 发现 b 不在  N1  上，将  add(a，b) 转发给 Global Scheduler
2. Global Scheduler 在 GCS 中查找 add(a，b) 的自变量的位置
3. Global Scheduler  决定在存储自变量 b 的节点 N2 上调度任务
4. 节点 N2 处的 Local Scheduler  检查 Local Object Store 是否包含 add(a，b) 的自变量
5. 节点 N2 处的 Local Scheduler 发现 Local Object Store 没有 objetc a，它在 GCS 中查找 a 的位置 
6. N2 Local Scheduler  得知 a 存储在 N1，N2 的 Object Store 复制它到本地
7. 由于add() 的所有参数现在都存储在 Local Object Store，所以Local Scheduler  在 Local Worker 调用 add()
8. N2 Local Worker 通过共享内存访问参数并执行
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray6.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;font-colorffa500论文结果-fontcenter&#34;&gt;&lt;font color=#FFA500&gt;&lt;strong&gt;论文结果&lt;/strong&gt; &lt;/font&gt;&lt;/center&gt;&lt;/h4&gt;
&lt;p&gt;Ray 中 GCS 的主要优势是增强系统的横向可扩展性。在实验中可以观察到几乎线性的任务吞吐量增长。在 60 节点，Ray 可以达到超过每秒 100 万个任务的吞吐量，并线性地在 100 个节点上超过每秒 180 万个任务。最右边的数据点显示，Ray 可以在不到一分钟的时间处理 1 亿个任务（54s）&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray7.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;论文用 Ray 实现了两种 RL 算法：Evolution Strategies (ES) 和 Proximal Policy Optimization(PPO)，然后与专为这两种算法设计的系统进行对比，Ray 可以赶上，甚至在更多的 GPU 下可以超越特定的系统。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray8.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Ray 是一个通用的分布式机器学习任务调度框架，Ray 通过将计算任务抽象为 Stateless  Task 和  Stateful Actor 支持了 Data Processing、Training、Serving 和Simulation 多种不同的机器学习任务类型。&lt;/p&gt;
&lt;p&gt;Ray 通过全局存储机制，自底向上的两段式调度来实现 Stateless  Task 和  Stateful Actor 的执行计算。同时系统所有的控制状态都存储在 GSC 中，其他组件可以很方便地进行扩展，并且在设计中考虑了容错和低延时。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;论文链接：&lt;a href=&#34;https://www.usenix.org/system/files/osdi18-moritz.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.usenix.org/system/files/osdi18-moritz.pdf&lt;/a&gt;
代码链接：&lt;a href=&#34;https://github.com/ray-project/ray&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/ray-project/ray&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 &lt;a href=&#34;https://github.com/IntelligentDDS/awesome-papers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/IntelligentDDS/awesome-papers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT 后面的分布式 AI 框架：Alpa</title>
      <link>https://yuxiaoba.github.io/post/alpa/</link>
      <pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://yuxiaoba.github.io/post/alpa/</guid>
      <description>&lt;p&gt;随着以 ChatGPT 为代表的大模型（LLM）技术的迅速发展，越来越多的企业和研究团队将目光聚焦于如何将大模型技术应用于自己的行业中，各种各样针对性的 Prompt 方法被提出来提高大模型技术在特定领域的适用性，以提高大模型技术的可靠性。除了提高 LLM 技术的适用性之外，我们还需要一个高性能且易于使用的机器学习基础设施来支撑 LLM 的训练和推理。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./model.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;现代 LLM 的参数大小为数千亿，例如， OPT-175B 模型需要 350GB 的 GPU 内存来容纳模型参数，这已经超过了单个设备或主机的 GPU 内存，而即使是当前最先进的 NVIDIA A100 和 H100 GPU 显卡也仅只有 40GB / 80GB GPU 内存。因此，为了能够高效地运行 LLM 的训练和推理任务，工程师需要对模型进行划分，然后将子模型调度到能够满足计算内存需求的 GPU 主机上进行并行计算。&lt;/p&gt;
&lt;p&gt;也就是说，对 LLM 的划分和编排调度成为了 LLM 的训练和推理的关键。下图展示了 NIVIDA 推荐的 LLM 训练和推理任务计算的技术栈。自顶向下来看，在开发人员对模型进行定义后，我们可以用 Alpa 对模型进行自动化的并行划分，然后基于 Ray 编排调度子任务，最后再由 GPU 显卡运行每个子任务。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./llm-stack.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;今天我们先来分享由 UC Berkeley 提出的 Alpa 框架，等夏至我们将继续分享 另外一个 Ray 的框架。Alpa 的原型是来自于 2022 年 UC Berkeley Rise Lab 团队发表在 CCF A 类的操作系统顶级会议 OSDI 上的论文 Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning。&lt;/p&gt;
&lt;h3 id=&#34;centerfont-colorffa5002022_osdi_alpa-automating-inter--and-intra-operator-parallelism-for-distributed-deep-learningfontcenter&#34;&gt;&lt;center&gt;&lt;font color=#FFA500&gt;2022_OSDI_Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning&lt;/font&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h4 id=&#34;论文背景&#34;&gt;&lt;strong&gt;论文背景&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa1.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在训练大模型的时候，我们通常会遇到两个与 “大” 相关的问题：一是输入的数据集非常大，二是模型非常大。&lt;/p&gt;
&lt;p&gt;对于输入的数据集非常大的问题，我们可以通过对数据的并行处理，将输入的数据划分成多个数据集，然后在每个机器上单独进行训练。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;但如果输入的模型非常大呢？ 例如单个 GPU 最大内存是  32 GB，而模型需要  350 GB  进行存储，这个时候单个  GPU  是无法满足训练的需求的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这个时候问题就变成了如何对 Computational graph 进行划分和编排调度，让一个大模型的子任务能够并行地运行在有限内存的  GPU  设备上，最后再对子任务的结果进行组合获得最终的结果。&lt;/p&gt;
&lt;h4 id=&#34;论文动机&#34;&gt;&lt;strong&gt;论文动机&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;对给定一个 computational graph 和对应的  GPU  设备，&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa4.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;典型的 computational graph 划分方式有 2 种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Inter-operator Parallelism：算子（operator）间并行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa5.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Intra-operator Parallelism：算子（operator）内并行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa6.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这两种并行方式各有优缺点，Inter-operator Parallelism 的方式可能会因为算子之间的等待导致更多的空闲设备，而 Intra-operator Parallelism 则会因为算子内部的数据分发导致更多的数据传输成本。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa7.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;为了克服以上两种并行方式的缺陷，我们可以很直观地想到可以将 Intra-op erator and Inter-operator Parallelism 组合起来，实现在最少的数据传输成本的条件下利用到更多的设备，从而尽快地训练完模型，这就是本文最核心的动机。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa8.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;论文方法&#34;&gt;&lt;strong&gt;论文方法&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;基于将 Intra-operator and Inter-operator Parallelism 组合起来加速模型训练的动机，论文提出了一个自动为大型 Deep Learning 模型找到并执行最佳的 Intra-operator and Inter-operator Parallelism 的编译器：Alpa。&lt;/p&gt;
&lt;p&gt;Alpa 以 computational graph 和  device cluster 作为输入，输出并行方案。下图展示了它的整体架构，自上而下可分为 Inter-operator Parallelism 负责解决如何划分 Stage ，Stage 间如何流水线并行。Intra-operator Parallelism 负责解决如何划分 Stage 中的算子内部然后并行运行到不同的设备上。最后  Runtime Orchestration 进行编译优化。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa9.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Inter-operator Parallelism&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 Inter-operator Parallelism 划分阶段，Alpa 首先将 Computational graph 划分成  Stage&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa10.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa11.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;然后 Alpa 以最小化 Pipeline 的运行延迟作为目标将 Stage 流水线化分配到多个设备上并行计算&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa12.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;对这个优化问题，Alpa 通过动态规划解决，具体的建模过程比较复杂，建议直接参考原论文&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa13.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Intra-operator Parallelism&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 Intra-operator Parallelism 划分阶段，Alpa 将每个 stage 中的 operator 进行进一步的划分。对于一个 operator，可以按 tensor 的行划分，也可以按  tensor 的列划分。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa14.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在  Intra-operator Parallelism 阶段，会由于不同算子之间按行或者按列划分导致额外的  Communication cost,  如将算子按列划分在  GPU0-3  并行计算完后，需要将结果发送到 GPU0 进行汇总。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa15.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;此外还包括 Re-partition Communication Cost， 如从按行划分转换为按列划分，有  All-Gather 的开销。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa16.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;其他的开销建议可以参考旷视研究院周亦庄博士 《利用MegEngine的分布式通信算子实现复杂的并行训练》的  PPT，这里不再详细分享。&lt;/p&gt;
&lt;p&gt;因此，在 Intra-operator Parallelism 除了考虑计算的开销外，还需考虑 communication cost 的开销，最后 Intra-operator Parallelism  的优化目标为最小化 computation  和 communication cost ， 然后 Alpa 用整数线性规划来解决此优化问题&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa17.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后将 Inter-operator 和  Intra-operator Parallelism 组合，即获得了 Alpa 最核心的分层优化方案&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa18.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Runtime Orchestration&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在编译阶段，Alpa 采用 MPMD 风格的运行时，为每个设备网格生成不同的静态执行指令序列&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa19.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;论文结果&#34;&gt;&lt;strong&gt;论文结果&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Alpa 基于Jax、HLO、RAY 实现完整的框架并开源到 &lt;a href=&#34;https://github.com/alpa-projects/alpa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/alpa-projects/alpa&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa20.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Alpa 在使用时只需要在函数前加一句  @alpa.parallelize 即可&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa21.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;论文首先与之前的工作对比了不同调优方式的吞吐量，可以发现 Alpa 可以与最优的手动调整获得相似的结果，而且通用性更高&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa22.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;论文然后做了 Inter-Operator 和 Intra-Operator 的消融实验，整合了 Inter-Operator 和 Intra-Operator 的 Alpa 能够获得更高的吞吐&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa23.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;将神经网络扩展到数千亿个参数，使得GPT-3等取得了巨大的突破，但训练和服务这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。 它只用几行代码就能实现大规模分布式训练和推理的并行自动化。&lt;/p&gt;
&lt;p&gt;Alpa 是一篇工作量非常大的论文，在上文中，我们只是简单的介绍了  Alpa 的核心思想，原文的内容远比我们介绍的复杂，同时论文的工程量也是相当的大，绝对是一篇  OSDI  级别的优秀论文。这就是国际上顶尖的研究团队。&lt;/p&gt;
&lt;p&gt;Alpa 开源一年目前在Github 上已经有超过 2.5K 的Star，背靠   UC Berkeley Rise Lab 和  Ray ，我们有理由相信它还会有更好的发展，让我们一起期待它的未来吧～&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;论文链接：&lt;a href=&#34;https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf&lt;/a&gt;
代码链接：&lt;a href=&#34;https://github.com/alpa-projects/alpa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/alpa-projects/alpa&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 &lt;a href=&#34;https://github.com/IntelligentDDS/awesome-papers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/IntelligentDDS/awesome-papers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ICSE 2023 最新成果：颠覆传统云故障处理方法，GPT 大型语言模型引领未来</title>
      <link>https://yuxiaoba.github.io/post/icse2023_1/</link>
      <pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://yuxiaoba.github.io/post/icse2023_1/</guid>
      <description>&lt;p&gt;今天我们来分享 ICSE 2023 上 Microsoft 团队发表的一篇将 GPT-3.x 应用在AIOps 领域的一篇论文 Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models。&lt;/p&gt;
&lt;p&gt;CSE 全称为 International Conference on Software Engineering，是软件工程领域 CCF A 类会议，2023 年收到 796 篇投稿，录用了 209 篇，录用率为 26%。&lt;/p&gt;
&lt;h3 id=&#34;centerfont-colorffa5002023_icse_recommending-root-cause-and-mitigation-steps-for-cloud-incidents-using-large-language-modelsfontcenter&#34;&gt;&lt;center&gt;&lt;font color=#FFA500&gt;2023_ICSE_Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models&lt;/font&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt1.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;论文背景&#34;&gt;&lt;strong&gt;论文背景&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在大型的 IT 软件系统中，由于软件的变更、运维的操作和外部环境变化等诸多因素，经常出现各种类型的故障。在故障发生后，运维工程师需要快速地进行根因定位并采取相应的恢复措施，以保障系统的可用性。&lt;/p&gt;
&lt;p&gt;为了记录故障的全生命周期，运维工程师通过以文本和图片的形式记录故障的发生、检测、定位和修复过程，这个记录也被称为 Incident 。下图展现了一个典型的 Incident 样例。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;论文动机&#34;&gt;&lt;strong&gt;论文动机&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;从上面的图可以看出，故障的 incident 是一种自然语言的形式，GPT-3.x 对自然语言处理的成功让 Microsoft 的研究人员意识到，有可能将 GPT-3.x 应用到incident 分析中，即将 incident 的标题和摘要（如错误的信息，异常的表现）作为输入，自动化生成故障的根因和推荐故障修复的措施。&lt;/p&gt;
&lt;p&gt;为了将  GPT-3.x 应用到 incident 分析中， 作者收集了 Microsoft 中从2018年1月1日至2022年7月15日期间的超过 40,000 个 incident  数据，得到了 57,520 个根因定位样例和 8,300 个故障修复样例。然后制定了六个研究问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-3.x 是否能够有效诊断 incident 的根因？&lt;/li&gt;
&lt;li&gt;GPT-3.x 是否能够有效地推荐缓解 incident 的措施？&lt;/li&gt;
&lt;li&gt;是否需要对 GPT-3.x 进行微调以适应 incident 分析场景 ？&lt;/li&gt;
&lt;li&gt;Multi-task learning 能提高 GPT-3.x 模型在根因诊断和故障修复推荐方面的准确率吗？&lt;/li&gt;
&lt;li&gt;如果已确定根因， GPT-3.x 是否能找到更好的故障修复措施？&lt;/li&gt;
&lt;li&gt;GPT-3.x 更擅长处理 machine-detected incident 还是更擅长处理human-detected incident ？&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;论文方法&#34;&gt;&lt;strong&gt;论文方法&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;为了研究上面的六个问题，论文选取了两个当前最先进的 encoder-decoder 模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RoBERTa : 训练数据集只包含文本 NLP 模型&lt;/li&gt;
&lt;li&gt;CodeBERT：训练数据集包含文本和代码的 NLP 模型， 125M 个参数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外还选取了 4 个 OpenAI 的 GPT 模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Curie:  训练数据集包含文本的，速度最快的GPT-3 模型，6.7 Billion 个参数&lt;/li&gt;
&lt;li&gt;CodeX: 训练数据集包含文本和代码的 GPT-3 模型， 12 Billion 个参数&lt;/li&gt;
&lt;li&gt;Davinci: 训练数据集只包含文本的 GPT-3.5 模型，175 Billion 个参数&lt;/li&gt;
&lt;li&gt;Code-davinci-002:  训练数据集包含文本和代码的 GPT-3.5 模型，175 Billion个参数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在根因定位方面，论文选择了 35820， 3000，2000 根因案例作为 training，testing ，validation。&lt;/p&gt;
&lt;p&gt;在故障恢复推荐方面，论文选择了 5455， 2000， 500 故障恢复案例作为training，testing ，validation。&lt;/p&gt;
&lt;p&gt;为了验证方法的效果，论文还设置了六个 NLP 领域的指标 BLEU-4，ROUGE-L，METEOR，BERTScore，BLEURT，NUBIA。这六个指标解释起来有点复杂，简单的说，它们都是衡量生成的文本与参考的文本的相似程度，相似程度越高得分越高，说明与实际的根因定位和修复策略越接近。&lt;/p&gt;
&lt;p&gt;除此之外，论文还将最近 2 个月的 50 个 incident 的结果与 incident 对应负责人进行采访，让他们对结果的正确性和可读性进行打分。&lt;/p&gt;
&lt;h4 id=&#34;论文结果&#34;&gt;&lt;strong&gt;论文结果&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;GPT-3.x 是否能够有效诊断 incident 的根因？
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;直观地看上表，我们可以发现 GPT-3.x  的结果似乎与 BERT 模型的结果相差不大。文章解释说是因为：NLP 的指标不适用于对根因定位和故障修复措施的衡量。例如 “代码中有一个bug” 是 incident 中非常常见和通用的句子，可能是任何根因的一部分，因此 BERT 模型只需复制特定的字段就可以最大限度地提高准确率。&lt;/p&gt;
&lt;p&gt;虽然 NLP 指标的结果差不多，但是作者在采访中发现，大多被采访者抱怨 BERT 模型返回的结果都是套路，例如返回 “代码中有一个bug”对故障的定位没有任何帮助。而 GPT-3.x  返回的结果则会更有针对性，更有利于根因定位。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;GPT-3.x 是否能够有效地推荐缓解 incident 的措施？
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt4.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

在故障修复措施这里，结果也是类似的， GPT-3.x  的结果似乎与 BERT 模型的结果相差不大。这是因为 incident 的故障修复措施中同样包含一些常见的句子如 “问题自行缓解”，“已部署到所有地区” ，导致总是把这些句子输出就获得了一个不错的结果，但是这些句子没有用处。但总的来说， GPT-3.x 的结果还是会好一些。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;是否需要对 GPT-3.x 进行微调以适应 incident 分析场景 ？
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt5.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

通用的 GPT-3 模型 pre-train 数据集中是不包含 incident 数据的，为了让它适应 incident 的场景，作者在 training 的数据集中使用包含 incident 数据对模型进行 find-tuned。从上表中可以发现，微调后的模型是要比没有微调的结果要好。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multi-task learning  能提高 GPT-3.x 模型在根因诊断和故障修复推荐方面的准确率吗？
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt6.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

前面的 GPT 模型是将根因定位和故障修复的任务分开训练，这一块论文将两个任务的训练数据作为输入一起训练，然后使用相应的测试集分别测试模型。总的来说，从表 V 中可以观察到 Multi-task learning 并没有显著优于单任务。论文认为这主要是因为根因和缓解措施之间缺乏联系。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果已确定根因， GPT-3.x 是否能找到更好的缓解措施？
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt7.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

上表的结果说明额外的根因信息可以给故障修复带来的相当大的性能增益。也就是说，如果根因定位准确， GPT-3.x 能找到更好的缓解措施。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPT-3.x 更擅长处理 machine-detected incident 还是更擅长处理human-detected incident ？
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt8.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

上表的结果表明 machine-detected incident  的结果可以比 human-detected incident 更好。这是因为 machine-detected incident 通常遵循某些模式，这些模式更容易被机器学习模型识别。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;微软工程师对 GPT 生成结果的反馈采访
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt9.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./gpt10.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

上表中 incident 负责人为 RoBERTa 和 CodeBERT 模型打了较低的正确性分数。尽管 GPT-3.x 的正确性得分在 2.28 到 3.16 之间，但工程师指出，GPT-3.x 模型推荐了有效的根因和缓解措施，或者可以给予工程师有价值的建议。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;论文小结&#34;&gt;&lt;strong&gt;论文小结&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;最后再来小结一下，本篇论文是我看到的在 AIOps 领域第一个使用 LLM 大模型的探索工作，论文对微软超过 40,000 个 incident 进行研究，证明先进的大型语言模型，可以有效地帮助 incident 管理，特别是在根因诊断和故障修复推荐方面。&lt;/p&gt;
&lt;p&gt;这项工作是一个门槛非常高的工作，数据集、模型训练的成本都不是我这种小 Phd 可以完成的，非常羡慕能够完成一个这样的工作。同时也非常羡慕 Microsoft 的学术嗅觉，在我还没有意识到 GPT 的强悍之前，他们已经把工作做完了，这大概就是世界顶级团队。&lt;/p&gt;
&lt;p&gt;论文的开头画了一个大饼，需要输入故障的描述和表现就可以自动化生成故障的根因和修复措施。但是论文的实验结果又不是很客观，缺乏了一个合理的指标对结果进行量化，总体上感觉没有那么让人信服。如果能够提出一个可以量化本文结果的指标，那也是一个很大的贡献。&lt;/p&gt;
&lt;p&gt;现在的 GPT-4 据说已经是可以处理多模态的数据了，那么运维日常使用的 Metric、Trace 、 Log 等数据是不是也可以与 Incident 数据一起打包进模型里呢？也许我们苦苦追寻的基于多模态数据的根因定位就这么粗暴地被解决了。&lt;/p&gt;
&lt;p&gt;除此之外，GPT 的可解释性是比较差的，日常的使用就会有一种一本正经地胡说八道的问题，如果在故障处理的时候，它一本正经地胡说，很可能进行错误的指引，把工程师往坑里带，反而会延长故障的修复时间。用一种不是很可靠的方法，去解决可靠性的问题，多少还是感觉有点让人心慌。期待这个方向有更有意思的东西！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;论文链接：&lt;a href=&#34;https://arxiv.org/pdf/2301.03797.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/2301.03797.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 &lt;a href=&#34;https://github.com/IntelligentDDS/awesome-papers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/IntelligentDDS/awesome-papers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
