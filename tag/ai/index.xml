<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI | Welcome to Guangba&#39;s HomePage</title>
    <link>https://yuxiaoba.github.io/tag/ai/</link>
      <atom:link href="https://yuxiaoba.github.io/tag/ai/index.xml" rel="self" type="application/rss+xml" />
    <description>AI</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 21 Jun 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yuxiaoba.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>AI</title>
      <link>https://yuxiaoba.github.io/tag/ai/</link>
    </image>
    
    <item>
      <title>Chatgpt 后面的分布式 AI 框架：Ray</title>
      <link>https://yuxiaoba.github.io/post/ray/</link>
      <pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://yuxiaoba.github.io/post/ray/</guid>
      <description>&lt;p&gt;在上一次的推送 &lt;a href=&#34;https://yuxiaoba.github.io/post/alpa/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChatGPT 后面的分布式 AI 框架：Alpa&lt;/a&gt; 中，我们介绍了随着LLM 的发展，LLM 模型的参数已经超过了单个设备的 GPU 内存，为了能够高效地运行 LLM 的训练和推理任务，工程师可以使用 Alpa 对模型进行划分，然后将子任务调度到能够满足计算内存需求的 GPU 设备上进行计算。&lt;/p&gt;
&lt;p&gt;那对模型进行划分以后，由什么框架来进行调度呢？与 Spark 和 Alpa 一母同胞，同样出自 UC Berkeley RiseLab 的 Ray 是当前一个热门的选择。Ray 是 2017 年 RiseLab 开源的通用的分布式调度框架，目前在  Github 上已经超过  2 W Star, 蚂蚁金服、OpenAI 等公司都使用它来调度机器学习任务。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./llm-stack.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;今天我们分享的论文就是 Ray 的论文原型，2018  年 UC Berkeley Rise Lab 团队发表在 CCF A 类的操作系统顶级会议 OSDI 上的论文：Ray: A Distributed Framework for Emerging AI Applications。值得注意的是，论文是  2018  年的，经过几年的迭代，当前的最新的  Ray 版本与论文的原型存在部分差异，但核心思想是不变的。&lt;/p&gt;
&lt;h3 id=&#34;centerfont-colorffa5002018_osdi_ray-a-distributed-framework-for-emerging-ai-applicationsfontcenter&#34;&gt;&lt;center&gt;&lt;font color=#FFA500&gt;2018_OSDI_Ray: A Distributed Framework for Emerging AI Applications&lt;/font&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h4 id=&#34;论文背景&#34;&gt;&lt;strong&gt;论文背景&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;现代 AI 应用，如强化学习，它已经不是由一种机器学习任务组成，而是会包含多种机器学习任务，比如 Data Processing、Training、Serving 和Simulation 等。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray1.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;不同类型的任务对计算模型、状态和时延的需求不同，AI 工程师可能需要基于不同的框架去设计和执行任务，比如在 Training 时使用TensorFlow 框架, 在Simulation 时使用  MPI 框架。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在这种情况下，AI 工程师不仅需要熟悉众多的框架，而且框架之间进行信息传递和交互也并非易事。 Ray 基于此痛点，提出了一个通用的机器学习任务调度框架，它能够适应和调度多种机器学习任务。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;ray-框架&#34;&gt;&lt;strong&gt;Ray 框架&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Ray 采取一种新的可横向扩展的分布式结构。Ray 的结构由两部分组成：Application Layer 和 System Layer。Application Layer 实现 API 和计算模型，执行分布式计算任务。System Layer 负责任务调度和数据管理，来满足表现性能和容错的要求。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray4.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Application Layer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ray的 Application Layer 使用传统的 Driver-Worker 模式进行组织。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Driver：运行用户程序的进程&lt;/li&gt;
&lt;li&gt;Worker：执行指定的 stateless task&lt;/li&gt;
&lt;li&gt;Actor：执行指定的 stateful actor&lt;/li&gt;
&lt;li&gt;Local Scheduler：本地调度器，两级调度策略的第一级&lt;/li&gt;
&lt;li&gt;Object store：本地存储器，用于存储task输入输出结果。它是一个基于内存的对象存储，同节点的 worker 可以通过 shared mem 机制来获取数据&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;System  Layer&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Global Control Store (GSC) 维护整个系统的状态，他的核心是 KV 存储和基于 KV 存储的订阅发布机制。系统所有的控制状态都存储在 GSC 中，这样系统其他组件可以是无状态的。这不仅简化了对容错的支持（出现错误时，组件可以从 GSC 中读取最近状态并重新启动），也使得其他组件可以横向扩展&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Global Scheduler: 全局调度器，两级调度策略的第二级&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bottom-Up Distributed Scheduler:  如下图所示 Ray 调度时，首先 Driver 会提交 task 到 Local Scheduler，Local Scheduler 将 task 调度给 Local Worker，将完成不了的 task 提交到 Global Scheduler， Global Scheduler 会根据每个节点的资源和预期等待时间，决策任务的调度去向。预期的调度时间可以根据任务在队列中的时间，任务的网络IO耗时来决定。这些信息可以根据心跳机制来获取。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray5.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Ray Shedule Example&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示了由 Driver 调用 add.remote(a，b) 触发的逐步操作，其中 a 和 b 分别存储在节点 N1 和 N2 上。
N1 的 Driver 将 add(a，b)提交给 Local Scheduler&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. Local Scheduler 发现 b 不在  N1  上，将  add(a，b) 转发给 Global Scheduler
2. Global Scheduler 在 GCS 中查找 add(a，b) 的自变量的位置
3. 3. Global Scheduler  决定在存储自变量 b 的节点 N2 上调度任务
4. 节点 N2 处的 Local Scheduler  检查 Local Object Store 是否包含 add(a，b) 的自变量
5. 节点 N2 处的 Local Scheduler 发现 Local Object Store 没有 objetc a，它在 GCS 中查找 a 的位置 
6. N2 Local Scheduler  得知 a 存储在 N1，N2 的 Object Store 复制它到本地
7. 由于add() 的所有参数现在都存储在 Local Object Store，所以Local Scheduler  在 Local Worker 调用 add()
8. N2 Local Worker 通过共享内存访问参数并执行
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray6.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;论文结果&#34;&gt;&lt;strong&gt;论文结果&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Ray 中 GCS 的主要优势是增强系统的横向可扩展性。在实验中可以观察到几乎线性的任务吞吐量增长。在 60 节点，Ray 可以达到超过每秒 100 万个任务的吞吐量，并线性地在 100 个节点上超过每秒 180 万个任务。最右边的数据点显示，Ray 可以在不到一分钟的时间处理 1 亿个任务（54s）&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray7.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;论文用 Ray 实现了两种 RL 算法：Evolution Strategies (ES) 和 Proximal Policy Optimization(PPO)，然后与专为这两种算法设计的系统进行对比，Ray 可以赶上，甚至在更多的 GPU 下可以超越特定的系统。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ray8.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Ray 是一个通用的分布式机器学习任务调度框架，Ray 通过将计算任务抽象为 Stateless  Task 和  Stateful Actor 支持了 Data Processing、Training、Serving 和Simulation 多种不同的机器学习任务类型。&lt;/p&gt;
&lt;p&gt;Ray 通过全局存储机制，自底向上的两段式调度来实现 Stateless  Task 和  Stateful Actor 的执行计算。同时系统所有的控制状态都存储在 GSC 中，其他组件可以很方便地进行扩展，并且在设计中考虑了容错和低延时。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;论文链接：&lt;a href=&#34;https://www.usenix.org/system/files/osdi18-moritz.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.usenix.org/system/files/osdi18-moritz.pdf&lt;/a&gt;
代码链接：&lt;a href=&#34;https://github.com/ray-project/ray&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/ray-project/ray&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 &lt;a href=&#34;https://github.com/IntelligentDDS/awesome-papers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/IntelligentDDS/awesome-papers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ChatGPT 后面的分布式 AI 框架：Alpa</title>
      <link>https://yuxiaoba.github.io/post/alpa/</link>
      <pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://yuxiaoba.github.io/post/alpa/</guid>
      <description>&lt;p&gt;随着以 ChatGPT 为代表的大模型（LLM）技术的迅速发展，越来越多的企业和研究团队将目光聚焦于如何将大模型技术应用于自己的行业中，各种各样针对性的 Prompt 方法被提出来提高大模型技术在特定领域的适用性，以提高大模型技术的可靠性。除了提高 LLM 技术的适用性之外，我们还需要一个高性能且易于使用的机器学习基础设施来支撑 LLM 的训练和推理。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./model.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;现代 LLM 的参数大小为数千亿，例如， OPT-175B 模型需要 350GB 的 GPU 内存来容纳模型参数，这已经超过了单个设备或主机的 GPU 内存，而即使是当前最先进的 NVIDIA A100 和 H100 GPU 显卡也仅只有 40GB / 80GB GPU 内存。因此，为了能够高效地运行 LLM 的训练和推理任务，工程师需要对模型进行划分，然后将子模型调度到能够满足计算内存需求的 GPU 主机上进行并行计算。&lt;/p&gt;
&lt;p&gt;也就是说，对 LLM 的划分和编排调度成为了 LLM 的训练和推理的关键。下图展示了 NIVIDA 推荐的 LLM 训练和推理任务计算的技术栈。自顶向下来看，在开发人员对模型进行定义后，我们可以用 Alpa 对模型进行自动化的并行划分，然后基于 Ray 编排调度子任务，最后再由 GPU 显卡运行每个子任务。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./llm-stack.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;今天我们先来分享由 UC Berkeley 提出的 Alpa 框架，等夏至我们将继续分享 另外一个 Ray 的框架。Alpa 的原型是来自于 2022 年 UC Berkeley Rise Lab 团队发表在 CCF A 类的操作系统顶级会议 OSDI 上的论文 Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning。&lt;/p&gt;
&lt;h3 id=&#34;centerfont-colorffa5002022_osdi_alpa-automating-inter--and-intra-operator-parallelism-for-distributed-deep-learningfontcenter&#34;&gt;&lt;center&gt;&lt;font color=#FFA500&gt;2022_OSDI_Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning&lt;/font&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h4 id=&#34;论文背景&#34;&gt;&lt;strong&gt;论文背景&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa1.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在训练大模型的时候，我们通常会遇到两个与 “大” 相关的问题：一是输入的数据集非常大，二是模型非常大。&lt;/p&gt;
&lt;p&gt;对于输入的数据集非常大的问题，我们可以通过对数据的并行处理，将输入的数据划分成多个数据集，然后在每个机器上单独进行训练。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;但如果输入的模型非常大呢？ 例如单个 GPU 最大内存是  32 GB，而模型需要  350 GB  进行存储，这个时候单个  GPU  是无法满足训练的需求的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这个时候问题就变成了如何对 Computational graph 进行划分和编排调度，让一个大模型的子任务能够并行地运行在有限内存的  GPU  设备上，最后再对子任务的结果进行组合获得最终的结果。&lt;/p&gt;
&lt;h4 id=&#34;论文动机&#34;&gt;&lt;strong&gt;论文动机&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;对给定一个 computational graph 和对应的  GPU  设备，&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa4.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;典型的 computational graph 划分方式有 2 种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Inter-operator Parallelism：算子（operator）间并行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa5.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Intra-operator Parallelism：算子（operator）内并行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa6.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这两种并行方式各有优缺点，Inter-operator Parallelism 的方式可能会因为算子之间的等待导致更多的空闲设备，而 Intra-operator Parallelism 则会因为算子内部的数据分发导致更多的数据传输成本。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa7.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;为了克服以上两种并行方式的缺陷，我们可以很直观地想到可以将 Intra-op erator and Inter-operator Parallelism 组合起来，实现在最少的数据传输成本的条件下利用到更多的设备，从而尽快地训练完模型，这就是本文最核心的动机。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa8.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;论文方法&#34;&gt;&lt;strong&gt;论文方法&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;基于将 Intra-operator and Inter-operator Parallelism 组合起来加速模型训练的动机，论文提出了一个自动为大型 Deep Learning 模型找到并执行最佳的 Intra-operator and Inter-operator Parallelism 的编译器：Alpa。&lt;/p&gt;
&lt;p&gt;Alpa 以 computational graph 和  device cluster 作为输入，输出并行方案。下图展示了它的整体架构，自上而下可分为 Inter-operator Parallelism 负责解决如何划分 Stage ，Stage 间如何流水线并行。Intra-operator Parallelism 负责解决如何划分 Stage 中的算子内部然后并行运行到不同的设备上。最后  Runtime Orchestration 进行编译优化。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa9.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Inter-operator Parallelism&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 Inter-operator Parallelism 划分阶段，Alpa 首先将 Computational graph 划分成  Stage&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa10.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa11.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;然后 Alpa 以最小化 Pipeline 的运行延迟作为目标将 Stage 流水线化分配到多个设备上并行计算&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa12.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;对这个优化问题，Alpa 通过动态规划解决，具体的建模过程比较复杂，建议直接参考原论文&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa13.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Intra-operator Parallelism&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 Intra-operator Parallelism 划分阶段，Alpa 将每个 stage 中的 operator 进行进一步的划分。对于一个 operator，可以按 tensor 的行划分，也可以按  tensor 的列划分。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa14.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在  Intra-operator Parallelism 阶段，会由于不同算子之间按行或者按列划分导致额外的  Communication cost,  如将算子按列划分在  GPU0-3  并行计算完后，需要将结果发送到 GPU0 进行汇总。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa15.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;此外还包括 Re-partition Communication Cost， 如从按行划分转换为按列划分，有  All-Gather 的开销。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa16.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;其他的开销建议可以参考旷视研究院周亦庄博士 《利用MegEngine的分布式通信算子实现复杂的并行训练》的  PPT，这里不再详细分享。&lt;/p&gt;
&lt;p&gt;因此，在 Intra-operator Parallelism 除了考虑计算的开销外，还需考虑 communication cost 的开销，最后 Intra-operator Parallelism  的优化目标为最小化 computation  和 communication cost ， 然后 Alpa 用整数线性规划来解决此优化问题&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa17.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后将 Inter-operator 和  Intra-operator Parallelism 组合，即获得了 Alpa 最核心的分层优化方案&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa18.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Runtime Orchestration&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在编译阶段，Alpa 采用 MPMD 风格的运行时，为每个设备网格生成不同的静态执行指令序列&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa19.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;论文结果&#34;&gt;&lt;strong&gt;论文结果&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Alpa 基于Jax、HLO、RAY 实现完整的框架并开源到 &lt;a href=&#34;https://github.com/alpa-projects/alpa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/alpa-projects/alpa&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa20.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Alpa 在使用时只需要在函数前加一句  @alpa.parallelize 即可&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa21.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;论文首先与之前的工作对比了不同调优方式的吞吐量，可以发现 Alpa 可以与最优的手动调整获得相似的结果，而且通用性更高&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa22.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;论文然后做了 Inter-Operator 和 Intra-Operator 的消融实验，整合了 Inter-Operator 和 Intra-Operator 的 Alpa 能够获得更高的吞吐&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./alpa23.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;将神经网络扩展到数千亿个参数，使得GPT-3等取得了巨大的突破，但训练和服务这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。 它只用几行代码就能实现大规模分布式训练和推理的并行自动化。&lt;/p&gt;
&lt;p&gt;Alpa 是一篇工作量非常大的论文，在上文中，我们只是简单的介绍了  Alpa 的核心思想，原文的内容远比我们介绍的复杂，同时论文的工程量也是相当的大，绝对是一篇  OSDI  级别的优秀论文。这就是国际上顶尖的研究团队。&lt;/p&gt;
&lt;p&gt;Alpa 开源一年目前在Github 上已经有超过 2.5K 的Star，背靠   UC Berkeley Rise Lab 和  Ray ，我们有理由相信它还会有更好的发展，让我们一起期待它的未来吧～&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;论文链接：&lt;a href=&#34;https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf&lt;/a&gt;
代码链接：&lt;a href=&#34;https://github.com/alpa-projects/alpa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/alpa-projects/alpa&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 &lt;a href=&#34;https://github.com/IntelligentDDS/awesome-papers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/IntelligentDDS/awesome-papers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
