[{"authors":null,"categories":null,"content":"I am Guangba Yu (余广坝 in Chinese). I am a 4th year Ph.D. candidate at Sun Yat-Sen University, advised by Professor Pengfei Chen. I am interested in cloud native, microservice, Serverless, and AIOps. My research focus on perfromance diagnose and optimization in distributed systems. And I have a strong curiosity about telemetry of cloud-native systems.\nI have awarded Tencent Rhino-Bird Research Elite Program and Tencent Special Scholarship in 2022. I am a Ph.D. software engineering student researcher at WeChat in 2022, hosted by Yuetang Deng.\nI am actively looking for faculty positions and post-doc opportunities. You can find more information in my CV.\nI maintain a Github project about Awesome cloud paper and a WeChat public account WeeklyCloudPaper in Chinese. Welcome to follow my updates.\n","date":1707264000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1707264000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am Guangba Yu (余广坝 in Chinese). I am a 4th year Ph.D. candidate at Sun Yat-Sen University, advised by Professor Pengfei Chen. I am interested in cloud native, microservice, Serverless, and AIOps.","tags":null,"title":"Guangba Yu","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://yuxiaoba.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Hongyang Chen","Pengfei Chen","Guangba Yu","Xiaoyun Li","Zilong He","Huxing Zhang"],"categories":null,"content":"The blow figure shows the framework of FaaSDeliver.   ","date":1707264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707264000,"objectID":"4a6e56f0d7f311796f0b68916f924aec","permalink":"https://yuxiaoba.github.io/publication/microfi24/","publishdate":"2024-02-07T00:00:00Z","relpermalink":"/publication/microfi24/","section":"publication","summary":"This paper presents MicroFI, a non-intrusive fault injection framework, aiming to efficiently test different application functions with request-level injection. Request-level injection limits the blast radius to specified requests without any source code modification.","tags":["Micoservice","Fault Injection"],"title":"MicroFI: Non-Intrusive and Prioritized Request-Level Fault Injection for Microservice Applications","type":"publication"},{"authors":["Guangba Yu","Pengfei Chen","Zilong He","Qiuyu Yan","Yu Luo","Fangyan Li","Zibin Zheng"],"categories":null,"content":"The blow figure shows the framework of ChangeRCA.   ","date":1705885200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705885200,"objectID":"ea5dad164c342fadee5bf4649ad3c937","permalink":"https://yuxiaoba.github.io/publication/changerca24/","publishdate":"2024-01-22T01:00:00Z","relpermalink":"/publication/changerca24/","section":"publication","summary":"To address the limitations of ACD, we propose a novel concept called root cause change analysis (RCCA) to identify the underlying root causes of change inducing incidents. In order to apply the RCCA concept to practical scenarios, we have devised an intelligent RCCA framework named ChangeRCA. This framework aims to localize the defective change associated with change-inducing incidents among multiple changes.","tags":["Root Cause Analysis","Software Change","Microservice"],"title":"ChangeRCA: Finding Root Causes from Software Changes in Large Online Systems","type":"publication"},{"authors":["Haiyu Huang","Xiaoyu Zhang","Pengfei Chen","Zilong He","Zhiming Chen","Guangba Yu","Hongyang Chen","Chen Sun"],"categories":null,"content":"The blow figure shows the framework of TraStariner.   ","date":1705798800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705798800,"objectID":"8b9b9880f29f967a01cc3c120bee8bcd","permalink":"https://yuxiaoba.github.io/publication/trastariner/","publishdate":"2024-01-21T01:00:00Z","relpermalink":"/publication/trastariner/","section":"publication","summary":"In this study, we introduce TraStrainer, an online sampler that takes into account both system runtime state and trace diversity. TraStrainer employs an interpretable and automated encoding method to represent traces as vectors. Simultaneously, it adaptively determines sampling preferences by analyzing system runtime metrics. When sampling, it combines the results of system-bias and diversity-bias through a dynamic voting mechanism.","tags":["Trace","Trace Sampling","Microservice"],"title":"TraStrainer: Adaptive Sampling for Distributed Traces with System Runtime State","type":"publication"},{"authors":["Wanqi Yang","Pengfei Chen","Guangba Yu","Haibin Zhang","Huxing Zhang"],"categories":null,"content":"The blow figure shows the framework of Deeppower.   ","date":1702339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702339200,"objectID":"2aa205526210469966cdc0444e7a07bd","permalink":"https://yuxiaoba.github.io/publication/servicemesh/","publishdate":"2023-12-12T00:00:00Z","relpermalink":"/publication/servicemesh/","section":"publication","summary":"This paper proposes a non-intrusive solution that enables packets to bypass the kernel network stack through the implementation of socket redirection and tc (traffic control) redirection with eBPF (extended Berkeley Packet Filter).","tags":["eBPF","Service Mesh"],"title":"Network shortcut in data plane of service mesh with eBPF","type":"publication"},{"authors":["Guangba Yu","Pengfei Chen","Yufeng Li","Hongyang Chen","Xiaoyun Li","Zibin Zheng"],"categories":null,"content":"The blow figure shows the framework of Nezha.   ","date":1690506000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690506000,"objectID":"993ed06515e873978a169a67845dd37f","permalink":"https://yuxiaoba.github.io/publication/nezha23/","publishdate":"2023-07-28T01:00:00Z","relpermalink":"/publication/nezha23/","section":"publication","summary":"In this study, we present Nezha, an interpretable and fine-grained RCA approach that pinpoints root causes at the code region and resource type level by incorporative analysis of multi-modal data. Nezha transforms heterogeneous multi-modal data into a homogeneous event representation and extracts event patterns by constructing and mining event graphs. The core idea of Nezha is to compare event patterns in the fault-free phase with those in the fault-suffering phase to localize root causes in an interpretable way.","tags":["Root Cause Analysis","Multi-modal Observability Data","Microservice"],"title":"Nezha: Interpretable Fine-Grained Root Causes Analysis for Microservices on Multi-Modal Observability Data","type":"publication"},{"authors":["Zhiming Chen","Pengfei Chen","Peipei Wang","Guangba Yu","Zilong He","Genting Mai"],"categories":null,"content":"The blow figure shows the framework of Diagconfig.   ","date":1690502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690502400,"objectID":"d01b5f15f67bbf49907e79449d3ca5af","permalink":"https://yuxiaoba.github.io/publication/diagconfig23/","publishdate":"2023-07-28T00:00:00Z","relpermalink":"/publication/diagconfig23/","section":"publication","summary":"This paper proposes DiagConfig, specifically designed to conduct configuration diagnosis of performance violations. It leverages static code analysis to track configuration option propagation, identifies performance-sensitive options, detects performance violations, and constructs cause-effect chains that help stakeholders better understand the relationship between configuration and performance violations.","tags":["Configuration diagnosis","Static analysis","Performance violation","Taint tracking"],"title":"DiagConfig: Configuration Diagnosis of Performance Violations in Configurable Software Systems","type":"publication"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"International Conference on Parallel Processing （ICPP）并行处理国际会议是世界上历史最悠久的并行计算学术会议之一，今已经在全球连续举办了52届。ICPP 被中国计算机学会（CCF）推荐国际学术会议列表认定为B类会议，是计算机并行计算领域最有学术影响力的顶级会议之一。\nICPP 2023 将于2023年8月7日至10日在犹他州盐湖城举行，我们实验室这次共有两篇论文被接收为长文。下面我们首次曝光这两个工作，欢迎大家关注我们的公众号，我们会持续推送最新的研究进展。\n MARS: Fault Localization in Programmable Networking Systems with Low-cost In-Band Network Telemetry    论文背景 在大规模数据中心中，除了服务器外，网络设备是重要的组成部分。软件定义网络（Software Defined Network，SDN）是由美国斯坦福大学 CLean State课题研究组提出的一种新型网络创新架构，是网络虚拟化的一种实现方式。其通过将网络设备的控制面与数据面分离开来，实现了网络流量的灵活控制。如今 SDN 交换机已被各大云数据中心广泛使用。\n由于一个 SDN 交换机通常负责一个区域的服务器网络，因此一旦 SDN 交换机出现故障，对上层应用的影响甚至大于服务器出现故障时的影响。因此在庞大的数据中心中，对 SDN 交换机进行实时监控和诊断对保证上层应用的可靠性来说非常重要。\n   但是当前的 SDN 交换机监控和诊断方法存在以下几个局限性：\n 当前的 SDN 交换机监控方法监控开销大，会带来额外的流量影响网络性能 当前的 SDN 交换机异常检测方法，依赖于静态阈值，需要大量的专家知识 当前的 SDN 交换机根因定位方法针对的故障类型有限，定位精度差  论文方法 为了克服已有工作的局限性，我们提出了一个端到端的 SDN 网络环境监控、异常检测、根因定位系统：MARS。下图展现了 MARS 的整体架构。\n   MARS 的贡献主要包括以下几点：\n 按需监控：我们提出了一种新颖的路径感知方法来监控网络流量并按需报告数据。这种方法与网络传输路径的长度无关，不会随着网络规模的增大而产生额外的开销。 自适应异常检测：我们提出了一种利用 reservoir model 自适应更新网络控制面中的阈值来进行 In-Network 异常检测的方法 自动化根因定位，我们将将频繁序列挖掘和基于 Spectrum 的故障定位结合起来，实现了多个层次（flow level, switch level, and port level）的自动化根因定位 。  论文实验    与对比方法相比，MARS 具有最小的 Bandwidth 开销和最小的 Diagnosis 开销。尽管 SpiderMon 和 MARS 的 Bandwidth 开销相近，但 MARS 以更全面的方式收集信息，提供了更维度和更彻底的根本原因分析。\n   在根因定位方面，MARS 能够定位更多类型的故障，在 Top2 实现 95% 的召回率。\n 论文链接：https://yuxiaoba.github.io/publication/mars23/mars23.pdf\n  DeepPower: Deep Reinforcement Learning based Power Management for Latency Critical Applications in Multi-core Systems    论文背景 延迟敏感型(Latency-Critical) 应用是在现代数据中心中占有很高的比例，为用户提供电子支付、搜索等各种服务。Latency-Critical 顾名思义，是一种对延迟要求非常高（毫秒级）的应用，为了确保用户在短时间内收到响应，每个请求的尾部延迟应保持在特定水平以下，通常为几毫秒。\n当前数据中心通常通过长期保持较高的 CPU 频率以满足延迟要求，但是这种方式会导致 CPU 利用率低和功耗过大。现代处理器的 Dynamic voltage/frequency scaling (DVFS) 技术可以我们在运行时以几微秒的延迟动态调整每个线程的CPU 频率。因此，一个直观的节省能耗的想法是在应用高负载时将CPU频率设置在高水平，以提高其在高负载下的计算能力，从而确保QoS要求。当应用负载较低时，降低 CPU 频率，从而降低整体功耗。这也是本文的核心思想。\n论文方法 本文提出了 DeepPower，它是一个为 Latency-Critical 应用设计的的基于深度强化学习（DRL）的能耗管理解决方案。如下图所示，DeepPower 由两个关键组件组成，一个用于监控系统负载变化的 DRL Agent 和一个用于CPU频率调整的 Thread Controller。DRL Agent 以较长的间隔调整 Thread Controller 的参数，而 Thread Controller 以较短的间隔调整CPU频率，实现分级 CPU 频率控制。\n   DeepPower 的贡献主要包括以下几点：\n 据我们所知，DeepPower 是第一个在 Latency-Critica 应用中使用 DRL进行能耗管理的方法。由于 DRL 强大的学习能力，学习到的策略比启发式的方法更有效，从而使应用功耗降低更多 DeepPower 提出了一种分级 CPU 频率控制机制。DRL Agent 以较长的间隔调整 Thread Controller 的参数，而 Thread Controller 以较短的间隔调整CPU频率。这种控制机制使 DeepPower 能够适应动态工作负载，并实现细粒度的频率调整  论文结果    与 Gemini 和 ReTail 等最先进的方法相比，DeepPower 可以在满足尾部延迟限制的同时降低 28.4% 的功耗 。\n   为了进一步了解DeepPower的优势，我们在图 9 中可视化了毫秒级延迟应用程序 Xapian 的运行过程，在图 10 中可视化了秒级延迟应用软件 Sphinx 。DeepPower 通过在请求处理过程中逐渐提高 CP频率来实现细粒度控制，如图 9a 和图 10a 所示。在请求处理期间，Thread Controller 缓慢地增加 CPU 频率。结果，CPU 频率在大部分时间内没有被提升到其最大水平。相反，Retail 和 Gemini 选择较粗粒度的频率（即，每个请求一次或两次）。这使得他们在许多情况下不得不提高CPU频率（即，出现长队列或请求超时），从而导致能耗更高。\n 论文链接：https://yuxiaoba.github.io/publication/deeppower23/deeppower23.pdf\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1688688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688688000,"objectID":"688501d27fe3751e0a927ecaa112a0da","permalink":"https://yuxiaoba.github.io/post/icpp23/","publishdate":"2023-07-07T00:00:00Z","relpermalink":"/post/icpp23/","section":"post","summary":"DDS 实验室两篇论文被并行计算领域的顶级学术会议ICPP（International Conference on Parallel Processing）接收为长文。”","tags":["Cloud Computing","Network","RCA","Power","Performance Optimiazation"],"title":"DDS 第一手研究曝光：ICPP 梅开二度","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"在上一次的推送 ChatGPT 后面的分布式 AI 框架：Alpa 中，我们介绍了随着LLM 的发展，LLM 模型的参数已经超过了单个设备的 GPU 内存，为了能够高效地运行 LLM 的训练和推理任务，工程师可以使用 Alpa 对模型进行划分，然后将子任务调度到能够满足计算内存需求的 GPU 设备上进行计算。\n那对模型进行划分以后，由什么框架来进行调度呢？与 Spark 和 Alpa 一母同胞，同样出自 UC Berkeley RiseLab 的 Ray 是当前一个热门的选择。Ray 是 2017 年 RiseLab 开源的通用的分布式调度框架，目前在 Github 上已经超过 2 W Star, 蚂蚁金服、OpenAI 等公司都使用它来调度机器学习任务。\n   今天我们分享的论文就是 Ray 的论文原型，2018 年 UC Berkeley Rise Lab 团队发表在 CCF A 类的操作系统顶级会议 OSDI 上的论文：Ray: A Distributed Framework for Emerging AI Applications。值得注意的是，论文是 2018 年的，经过几年的迭代，当前的最新的 Ray 版本与论文的原型存在部分差异，但核心思想是不变的。\n2018_OSDI_Ray: A Distributed Framework for Emerging AI Applications 论文背景  现代 AI 应用，如强化学习，它已经不是由一种机器学习任务组成，而是会包含多种机器学习任务，比如 Data Processing、Training、Serving 和Simulation 等。\n   不同类型的任务对计算模型、状态和时延的需求不同，AI 工程师可能需要基于不同的框架去设计和执行任务，比如在 Training 时使用TensorFlow 框架, 在Simulation 时使用 MPI 框架。\n   在这种情况下，AI 工程师不仅需要熟悉众多的框架，而且框架之间进行信息传递和交互也并非易事。 Ray 基于此痛点，提出了一个通用的机器学习任务调度框架，它能够适应和调度多种机器学习任务。\n   Ray 框架*  Ray 采取一种新的可横向扩展的分布式结构。Ray 的结构由两部分组成：Application Layer 和 System Layer。Application Layer 实现 API 和计算模型，执行分布式计算任务。System Layer 负责任务调度和数据管理，来满足表现性能和容错的要求。\n    Application Layer  Ray的 Application Layer 使用传统的 Driver-Worker 模式进行组织。\n Driver：运行用户程序的进程 Worker：执行指定的 stateless task Actor：执行指定的 stateful actor Local Scheduler：本地调度器，两级调度策略的第一级 Object store：本地存储器，用于存储task输入输出结果。它是一个基于内存的对象存储，同节点的 worker 可以通过 shared mem 机制来获取数据  System Layer    Global Control Store (GSC) 维护整个系统的状态，他的核心是 KV 存储和基于 KV 存储的订阅发布机制。系统所有的控制状态都存储在 GSC 中，这样系统其他组件可以是无状态的。这不仅简化了对容错的支持（出现错误时，组件可以从 GSC 中读取最近状态并重新启动），也使得其他组件可以横向扩展\n  Global Scheduler: 全局调度器，两级调度策略的第二级\n  Bottom-Up Distributed Scheduler: 如下图所示 Ray 调度时，首先 Driver 会提交 task 到 Local Scheduler，Local Scheduler 将 task 调度给 Local Worker，将完成不了的 task 提交到 Global Scheduler， Global Scheduler 会根据每个节点的资源和预期等待时间，决策任务的调度去向。预期的调度时间可以根据任务在队列中的时间，任务的网络IO耗时来决定。这些信息可以根据心跳机制来获取。\n     Ray Shedule Example  下图展示了由 Driver 调用 add.remote(a，b) 触发的逐步操作，其中 a 和 b 分别存储在节点 N1 和 N2 上。 N1 的 Driver 将 add(a，b)提交给 Local Scheduler\n1. Local Scheduler 发现 b 不在 N1 上，将 add(a，b) 转发给 Global Scheduler 2. Global Scheduler 在 GCS 中查找 add(a，b) 的自变量的位置 3. Global Scheduler 决定在存储自变量 b 的节点 N2 上调度任务 4. 节点 N2 处的 Local Scheduler 检查 Local Object Store 是否包含 add(a，b) 的自变量 5. 节点 N2 处的 Local Scheduler 发现 Local Object Store 没有 objetc a，它在 GCS 中查找 a 的位置 6. N2 Local Scheduler 得知 a 存储在 N1，N2 的 Object Store 复制它到本地 7. 由于add() 的所有参数现在都存储在 Local Object Store，所以Local Scheduler 在 Local Worker 调用 add() 8. N2 Local Worker 通过共享内存访问参数并执行     论文结果  Ray 中 GCS 的主要优势是增强系统的横向可扩展性。在实验中可以观察到几乎线性的任务吞吐量增长。在 60 节点，Ray 可以达到超过每秒 100 万个任务的吞吐量，并线性地在 100 个节点上超过每秒 180 万个任务。最右边的数据点显示，Ray 可以在不到一分钟的时间处理 1 亿个任务（54s）\n   论文用 Ray 实现了两种 RL 算法：Evolution Strategies (ES) 和 Proximal Policy Optimization(PPO)，然后与专为这两种算法设计的系统进行对比，Ray 可以赶上，甚至在更多的 GPU 下可以超越特定的系统。\n   Ray 是一个通用的分布式机器学习任务调度框架，Ray 通过将计算任务抽象为 Stateless Task 和 Stateful Actor 支持了 Data Processing、Training、Serving 和Simulation 多种不同的机器学习任务类型。\nRay 通过全局存储机制，自底向上的两段式调度来实现 Stateless Task 和 Stateful Actor 的执行计算。同时系统所有的控制状态都存储在 GSC 中，其他组件可以很方便地进行扩展，并且在设计中考虑了容错和低延时。\n 论文链接：https://www.usenix.org/system/files/osdi18-moritz.pdf 代码链接：https://github.com/ray-project/ray\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1687305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687305600,"objectID":"bd07c4c5de7c60d28782192effb8100c","permalink":"https://yuxiaoba.github.io/post/ray/","publishdate":"2023-06-21T00:00:00Z","relpermalink":"/post/ray/","section":"post","summary":"现代AI应用已经不再由一种机器学习任务组成，而由多种机器学习任务如 Data Processing、Training、Serving 和Simulation 组成。而当前没有一个能够同时支持多种类型任务的通用调度框架，工程师需要组合多种框架来开发应用。为了解决这个痛点，UC Berkeley 提出一个通用的分布式计算框架 Ray。","tags":["GPT","AI"],"title":"Chatgpt 后面的分布式 AI 框架：Ray","type":"post"},{"authors":["Jingrun Zhang","Guangba Yu","Zilong He","Liang Ai","Pengfei Chen"],"categories":null,"content":"The blow figure shows the framework of Deeppower.   ","date":1686873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686873600,"objectID":"4ae027a9789ea0a80d8daba01a739e36","permalink":"https://yuxiaoba.github.io/publication/deeppower23/","publishdate":"2023-06-16T00:00:00Z","relpermalink":"/publication/deeppower23/","section":"publication","summary":"This paper proposes DeepPower, a deep reinforcement learning (DRL) based power management solution for LC applications. DeepPower comprises two key components, a DRL agent for monitoring the system load changes and a thread controller for CPU frequency adjustment.","tags":["Power","Deep Reinforcement Learning"],"title":"DeepPower: Deep Reinforcement Learning based Power Management for Latency Critical Applications in Multi-core Systems","type":"publication"},{"authors":["Benran Wang","Hongyang Chen","Pengfei Chen","Zilong He","Guangba Yu"],"categories":null,"content":"The blow figure shows the framework of GIED.   ","date":1686873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686873600,"objectID":"3f0ff51260515b1544c89fde0e42bf17","permalink":"https://yuxiaoba.github.io/publication/mars23/","publishdate":"2023-06-16T00:00:00Z","relpermalink":"/publication/mars23/","section":"publication","summary":"In this paper, we present MARS, a lightweight system for anomaly detection with dynamic threshold and automatic root cause localization in programmable networking systems.","tags":["Network","AIOps","Reliability","RCA"],"title":"MARS: Fault Localization in Programmable Networking Systems with Low-cost In-Band Network Telemetry","type":"publication"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"随着以 ChatGPT 为代表的大模型（LLM）技术的迅速发展，越来越多的企业和研究团队将目光聚焦于如何将大模型技术应用于自己的行业中，各种各样针对性的 Prompt 方法被提出来提高大模型技术在特定领域的适用性，以提高大模型技术的可靠性。除了提高 LLM 技术的适用性之外，我们还需要一个高性能且易于使用的机器学习基础设施来支撑 LLM 的训练和推理。\n   现代 LLM 的参数大小为数千亿，例如， OPT-175B 模型需要 350GB 的 GPU 内存来容纳模型参数，这已经超过了单个设备或主机的 GPU 内存，而即使是当前最先进的 NVIDIA A100 和 H100 GPU 显卡也仅只有 40GB / 80GB GPU 内存。因此，为了能够高效地运行 LLM 的训练和推理任务，工程师需要对模型进行划分，然后将子模型调度到能够满足计算内存需求的 GPU 主机上进行并行计算。\n也就是说，对 LLM 的划分和编排调度成为了 LLM 的训练和推理的关键。下图展示了 NIVIDA 推荐的 LLM 训练和推理任务计算的技术栈。自顶向下来看，在开发人员对模型进行定义后，我们可以用 Alpa 对模型进行自动化的并行划分，然后基于 Ray 编排调度子任务，最后再由 GPU 显卡运行每个子任务。\n   今天我们先来分享由 UC Berkeley 提出的 Alpa 框架，等夏至我们将继续分享 另外一个 Ray 的框架。Alpa 的原型是来自于 2022 年 UC Berkeley Rise Lab 团队发表在 CCF A 类的操作系统顶级会议 OSDI 上的论文 Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning。\n2022_OSDI_Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning 论文背景    在训练大模型的时候，我们通常会遇到两个与 “大” 相关的问题：一是输入的数据集非常大，二是模型非常大。\n对于输入的数据集非常大的问题，我们可以通过对数据的并行处理，将输入的数据划分成多个数据集，然后在每个机器上单独进行训练。\n   但如果输入的模型非常大呢？ 例如单个 GPU 最大内存是 32 GB，而模型需要 350 GB 进行存储，这个时候单个 GPU 是无法满足训练的需求的。\n   这个时候问题就变成了如何对 Computational graph 进行划分和编排调度，让一个大模型的子任务能够并行地运行在有限内存的 GPU 设备上，最后再对子任务的结果进行组合获得最终的结果。\n论文动机 对给定一个 computational graph 和对应的 GPU 设备，\n   典型的 computational graph 划分方式有 2 种：\n Inter-operator Parallelism：算子（operator）间并行     Intra-operator Parallelism：算子（operator）内并行     这两种并行方式各有优缺点，Inter-operator Parallelism 的方式可能会因为算子之间的等待导致更多的空闲设备，而 Intra-operator Parallelism 则会因为算子内部的数据分发导致更多的数据传输成本。\n   为了克服以上两种并行方式的缺陷，我们可以很直观地想到可以将 Intra-op erator and Inter-operator Parallelism 组合起来，实现在最少的数据传输成本的条件下利用到更多的设备，从而尽快地训练完模型，这就是本文最核心的动机。\n   论文方法 基于将 Intra-operator and Inter-operator Parallelism 组合起来加速模型训练的动机，论文提出了一个自动为大型 Deep Learning 模型找到并执行最佳的 Intra-operator and Inter-operator Parallelism 的编译器：Alpa。\nAlpa 以 computational graph 和 device cluster 作为输入，输出并行方案。下图展示了它的整体架构，自上而下可分为 Inter-operator Parallelism 负责解决如何划分 Stage ，Stage 间如何流水线并行。Intra-operator Parallelism 负责解决如何划分 Stage 中的算子内部然后并行运行到不同的设备上。最后 Runtime Orchestration 进行编译优化。\n    Inter-operator Parallelism  在 Inter-operator Parallelism 划分阶段，Alpa 首先将 Computational graph 划分成 Stage\n      然后 Alpa 以最小化 Pipeline 的运行延迟作为目标将 Stage 流水线化分配到多个设备上并行计算\n   对这个优化问题，Alpa 通过动态规划解决，具体的建模过程比较复杂，建议直接参考原论文\n   Intra-operator Parallelism  在 Intra-operator Parallelism 划分阶段，Alpa 将每个 stage 中的 operator 进行进一步的划分。对于一个 operator，可以按 tensor 的行划分，也可以按 tensor 的列划分。\n   在 Intra-operator Parallelism 阶段，会由于不同算子之间按行或者按列划分导致额外的 Communication cost, 如将算子按列划分在 GPU0-3 并行计算完后，需要将结果发送到 GPU0 进行汇总。\n   此外还包括 Re-partition Communication Cost， 如从按行划分转换为按列划分，有 All-Gather 的开销。\n   其他的开销建议可以参考旷视研究院周亦庄博士 《利用MegEngine的分布式通信算子实现复杂的并行训练》的 PPT，这里不再详细分享。\n因此，在 Intra-operator Parallelism 除了考虑计算的开销外，还需考虑 communication cost 的开销，最后 Intra-operator Parallelism 的优化目标为最小化 computation 和 communication cost ， 然后 Alpa 用整数线性规划来解决此优化问题\n   最后将 Inter-operator 和 Intra-operator Parallelism 组合，即获得了 Alpa 最核心的分层优化方案\n   Runtime Orchestration  在编译阶段，Alpa 采用 MPMD 风格的运行时，为每个设备网格生成不同的静态执行指令序列\n   论文结果 Alpa 基于Jax、HLO、RAY 实现完整的框架并开源到 https://github.com/alpa-projects/alpa\n   Alpa 在使用时只需要在函数前加一句 @alpa.parallelize 即可\n   论文首先与之前的工作对比了不同调优方式的吞吐量，可以发现 Alpa 可以与最优的手动调整获得相似的结果，而且通用性更高\n   论文然后做了 Inter-Operator 和 Intra-Operator 的消融实验，整合了 Inter-Operator 和 Intra-Operator 的 Alpa 能够获得更高的吞吐\n   将神经网络扩展到数千亿个参数，使得GPT-3等取得了巨大的突破，但训练和服务这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。 它只用几行代码就能实现大规模分布式训练和推理的并行自动化。\nAlpa 是一篇工作量非常大的论文，在上文中，我们只是简单的介绍了 Alpa 的核心思想，原文的内容远比我们介绍的复杂，同时论文的工程量也是相当的大，绝对是一篇 OSDI 级别的优秀论文。这就是国际上顶尖的研究团队。\nAlpa 开源一年目前在Github 上已经有超过 2.5K 的Star，背靠 UC Berkeley Rise Lab 和 Ray ，我们有理由相信它还会有更好的发展，让我们一起期待它的未来吧～\n 论文链接：https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf 代码链接：https://github.com/alpa-projects/alpa\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1685923200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685923200,"objectID":"1deccd77b4d399bc141a629b858afe10","permalink":"https://yuxiaoba.github.io/post/alpa/","publishdate":"2023-06-05T00:00:00Z","relpermalink":"/post/alpa/","section":"post","summary":"将神经网络扩展到数千亿个参数，使得GPT-4等取得了巨大的突破，但训练和推理这些大规模的神经网络需要复杂的分布式系统技术。Alpa是一个适用于训练和推理大规模神经网络的自动化编译器。它只用几行代码就能实现大规模分布式训练和推理的并行自动化。","tags":["GPT","AI"],"title":"ChatGPT 后面的分布式 AI 框架：Alpa","type":"post"},{"authors":["Guangba Yu","Pengfei Chen","Zibin Zheng","Jingrun Zhang","Xiaoyun Li","Zilong He"],"categories":null,"content":"The blow figure shows the framework of FaaSDeliver.   ","date":1683417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683417600,"objectID":"484818d5a0d1b610500e8ed212e664d6","permalink":"https://yuxiaoba.github.io/publication/faasdeliver23/","publishdate":"2023-05-07T00:00:00Z","relpermalink":"/publication/faasdeliver23/","section":"publication","summary":"This paper proposes an adaptive and efficient function delivery engine, named FaaSDeliver, which automatically unearths a cost-efficient function delivery policy (FDP) for each function, including the FaaS platform selection and resource allocation.","tags":["Serverless Computing","Function as a Service","Computing Continuum","Online Learning"],"title":"FaaSDeliver: Cost-efﬁcient and QoS-aware Function Delivery in Computing Continuum","type":"publication"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今天我们来分享 ICSE 2023 上 Microsoft 团队发表的一篇将 GPT-3.x 应用在AIOps 领域的一篇论文 Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models。\nCSE 全称为 International Conference on Software Engineering，是软件工程领域 CCF A 类会议，2023 年收到 796 篇投稿，录用了 209 篇，录用率为 26%。\n2023_ICSE_Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models    论文背景 在大型的 IT 软件系统中，由于软件的变更、运维的操作和外部环境变化等诸多因素，经常出现各种类型的故障。在故障发生后，运维工程师需要快速地进行根因定位并采取相应的恢复措施，以保障系统的可用性。\n为了记录故障的全生命周期，运维工程师通过以文本和图片的形式记录故障的发生、检测、定位和修复过程，这个记录也被称为 Incident 。下图展现了一个典型的 Incident 样例。\n   论文动机 从上面的图可以看出，故障的 incident 是一种自然语言的形式，GPT-3.x 对自然语言处理的成功让 Microsoft 的研究人员意识到，有可能将 GPT-3.x 应用到incident 分析中，即将 incident 的标题和摘要（如错误的信息，异常的表现）作为输入，自动化生成故障的根因和推荐故障修复的措施。\n为了将 GPT-3.x 应用到 incident 分析中， 作者收集了 Microsoft 中从2018年1月1日至2022年7月15日期间的超过 40,000 个 incident 数据，得到了 57,520 个根因定位样例和 8,300 个故障修复样例。然后制定了六个研究问题：\n GPT-3.x 是否能够有效诊断 incident 的根因？ GPT-3.x 是否能够有效地推荐缓解 incident 的措施？ 是否需要对 GPT-3.x 进行微调以适应 incident 分析场景 ？ Multi-task learning 能提高 GPT-3.x 模型在根因诊断和故障修复推荐方面的准确率吗？ 如果已确定根因， GPT-3.x 是否能找到更好的故障修复措施？ GPT-3.x 更擅长处理 machine-detected incident 还是更擅长处理human-detected incident ？  论文方法 为了研究上面的六个问题，论文选取了两个当前最先进的 encoder-decoder 模型：\n RoBERTa : 训练数据集只包含文本 NLP 模型 CodeBERT：训练数据集包含文本和代码的 NLP 模型， 125M 个参数  此外还选取了 4 个 OpenAI 的 GPT 模型：\n Curie: 训练数据集包含文本的，速度最快的GPT-3 模型，6.7 Billion 个参数 CodeX: 训练数据集包含文本和代码的 GPT-3 模型， 12 Billion 个参数 Davinci: 训练数据集只包含文本的 GPT-3.5 模型，175 Billion 个参数 Code-davinci-002: 训练数据集包含文本和代码的 GPT-3.5 模型，175 Billion个参数  在根因定位方面，论文选择了 35820， 3000，2000 根因案例作为 training，testing ，validation。\n在故障恢复推荐方面，论文选择了 5455， 2000， 500 故障恢复案例作为training，testing ，validation。\n为了验证方法的效果，论文还设置了六个 NLP 领域的指标 BLEU-4，ROUGE-L，METEOR，BERTScore，BLEURT，NUBIA。这六个指标解释起来有点复杂，简单的说，它们都是衡量生成的文本与参考的文本的相似程度，相似程度越高得分越高，说明与实际的根因定位和修复策略越接近。\n除此之外，论文还将最近 2 个月的 50 个 incident 的结果与 incident 对应负责人进行采访，让他们对结果的正确性和可读性进行打分。\n论文结果  GPT-3.x 是否能够有效诊断 incident 的根因？     直观地看上表，我们可以发现 GPT-3.x 的结果似乎与 BERT 模型的结果相差不大。文章解释说是因为：NLP 的指标不适用于对根因定位和故障修复措施的衡量。例如 “代码中有一个bug” 是 incident 中非常常见和通用的句子，可能是任何根因的一部分，因此 BERT 模型只需复制特定的字段就可以最大限度地提高准确率。\n虽然 NLP 指标的结果差不多，但是作者在采访中发现，大多被采访者抱怨 BERT 模型返回的结果都是套路，例如返回 “代码中有一个bug”对故障的定位没有任何帮助。而 GPT-3.x 返回的结果则会更有针对性，更有利于根因定位。\n GPT-3.x 是否能够有效地推荐缓解 incident 的措施？   在故障修复措施这里，结果也是类似的， GPT-3.x 的结果似乎与 BERT 模型的结果相差不大。这是因为 incident 的故障修复措施中同样包含一些常见的句子如 “问题自行缓解”，“已部署到所有地区” ，导致总是把这些句子输出就获得了一个不错的结果，但是这些句子没有用处。但总的来说， GPT-3.x 的结果还是会好一些。\n  是否需要对 GPT-3.x 进行微调以适应 incident 分析场景 ？   通用的 GPT-3 模型 pre-train 数据集中是不包含 incident 数据的，为了让它适应 incident 的场景，作者在 training 的数据集中使用包含 incident 数据对模型进行 find-tuned。从上表中可以发现，微调后的模型是要比没有微调的结果要好。\n  Multi-task learning 能提高 GPT-3.x 模型在根因诊断和故障修复推荐方面的准确率吗？   前面的 GPT 模型是将根因定位和故障修复的任务分开训练，这一块论文将两个任务的训练数据作为输入一起训练，然后使用相应的测试集分别测试模型。总的来说，从表 V 中可以观察到 Multi-task learning 并没有显著优于单任务。论文认为这主要是因为根因和缓解措施之间缺乏联系。\n  如果已确定根因， GPT-3.x 是否能找到更好的缓解措施？   上表的结果说明额外的根因信息可以给故障修复带来的相当大的性能增益。也就是说，如果根因定位准确， GPT-3.x 能找到更好的缓解措施。\n  GPT-3.x 更擅长处理 machine-detected incident 还是更擅长处理human-detected incident ？   上表的结果表明 machine-detected incident 的结果可以比 human-detected incident 更好。这是因为 machine-detected incident 通常遵循某些模式，这些模式更容易被机器学习模型识别。\n  微软工程师对 GPT 生成结果的反馈采访     上表中 incident 负责人为 RoBERTa 和 CodeBERT 模型打了较低的正确性分数。尽管 GPT-3.x 的正确性得分在 2.28 到 3.16 之间，但工程师指出，GPT-3.x 模型推荐了有效的根因和缓解措施，或者可以给予工程师有价值的建议。\n  论文小结 最后再来小结一下，本篇论文是我看到的在 AIOps 领域第一个使用 LLM 大模型的探索工作，论文对微软超过 40,000 个 incident 进行研究，证明先进的大型语言模型，可以有效地帮助 incident 管理，特别是在根因诊断和故障修复推荐方面。\n这项工作是一个门槛非常高的工作，数据集、模型训练的成本都不是我这种小 Phd 可以完成的，非常羡慕能够完成一个这样的工作。同时也非常羡慕 Microsoft 的学术嗅觉，在我还没有意识到 GPT 的强悍之前，他们已经把工作做完了，这大概就是世界顶级团队。\n论文的开头画了一个大饼，需要输入故障的描述和表现就可以自动化生成故障的根因和修复措施。但是论文的实验结果又不是很客观，缺乏了一个合理的指标对结果进行量化，总体上感觉没有那么让人信服。如果能够提出一个可以量化本文结果的指标，那也是一个很大的贡献。\n现在的 GPT-4 据说已经是可以处理多模态的数据了，那么运维日常使用的 Metric、Trace 、 Log 等数据是不是也可以与 Incident 数据一起打包进模型里呢？也许我们苦苦追寻的基于多模态数据的根因定位就这么粗暴地被解决了。\n除此之外，GPT 的可解释性是比较差的，日常的使用就会有一种一本正经地胡说八道的问题，如果在故障处理的时候，它一本正经地胡说，很可能进行错误的指引，把工程师往坑里带，反而会延长故障的修复时间。用一种不是很可靠的方法，去解决可靠性的问题，多少还是感觉有点让人心慌。期待这个方向有更有意思的东西！\n 论文链接：https://arxiv.org/pdf/2301.03797.pdf\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1680652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680652800,"objectID":"bf44cabd1b2e3349aa4a3d979072e21e","permalink":"https://yuxiaoba.github.io/post/icse2023_1/","publishdate":"2023-04-05T00:00:00Z","relpermalink":"/post/icse2023_1/","section":"post","summary":"Microsoft 在国际顶级软件工程学术会议 ICSE 2023 最新成果：颠覆传统云故障处理方法，使用 GPT-3.x 大型语言模型对 incdent 进行分析，自动化生成根因定位结果和故障修复措施。","tags":["GPT","Trace"],"title":"ICSE 2023 最新成果：颠覆传统云故障处理方法，GPT 大型语言模型引领未来","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"WWW 全称 World Wide Web Conference，又称 The Web Conference，是一个CCF A 类的，旨在促进互联网技术的研究与发展国际性学术会议。\nWWW 的历史可以追溯到 1994 年，首次会议在瑞士日内瓦举行。该会议汇集了来自学术界、产业界、政府和非营利组织的研究人员、开发者和实践者，共同探讨和分享有关互联网技术的最新进展、创新应用和未来发展方向。\nWWW 2023 将于 2023年4月30日至5月4日在美国举行。本次会议共收到 1900 篇投稿， 录用了 365 篇，录用率为 19.2%。我们实验室投了一篇，做了分母。在这个链接 https://www2023.thewebconf.org/program/accepted-papers/ 中可以看到全部接收的 Paper。\n下面跟随本文追踪 WWW 2023 中云计算领域的最新研究吧。\n 01 2023_WWW_Diagnostor: An Ambiguity-Aware Root Cause Localization Approach Based on Call Metric Data    论文简介: 论文提出了一个无监督的通过分析服务之间 Call Metric 的因果关系进行根因定位方法 CMDiagnostor。这种指标根因定位的思路我们之前在 基于 Metrics 的根因定位 (二)：因果关系图 中概述过，它主要是通过Metrics 之间的依赖关系构建出调用关系图，然后基于相关性或随机游走算法在图上游走从而定位出根因。这种根因定位方法的准确性极大地依赖于调用关系图的构建是否准确。CMDiagnostor 的主要贡献就是优化了调用关系图的构建方式。\n传统的调用图构建方式受限于 Call Metric 的有限信息，构建出的调用图有可能会带有歧义（Ambiguity）。 这里的歧义如下图所示，（a）中是 Call Metric 中包含的调用关系，（b）是根据这些调用关系组合出来的调用图。但是（b）的调用图在实际的运行中，可能包含（c）中的多种可能的控制流，这就导致了文章所言的歧义。\n   如果没有对上文的歧义进行进一步的划分，因果关系图的构建是不够准确的，从而也会影响到根因定位的准确性。CMDiagnostor 提出了一种流量回归方法（称为AmSitor）来处理模糊性，并构建无模糊调用图。其核心思想是：将一个下游流量与其可能的上游流量进行线性回归，每个上游流量的回归系数可以被视为其期望值。具有低系数（例如，小于或等于 0.005）的上游将被剪枝掉。\n通过 AmSitor 进行剪枝，CMDiagnostor 就可以去除掉调用图中带有的歧义，剩下的根因定位过程（如下图所示）与我们之前分享的 MicroHECL 和 Microscope 大同小异，感兴趣也可看一下 基于 Metrics 的根因定位 (二)：因果关系图 。\n   这里 Precision 描述了一个 P 在 Test 阶段出现，不在 Control 阶段出现的概率，也就是说在 T 中频繁出现，在 C 中出现不频繁的 P 可疑得分更高。Recall 描述了 P 能覆盖多少 Test 阶段的 Trace，它表示了 P 在 Test 阶段的代表性，越有代表性越重要。最后为了综合考虑两个参数，一个 Frequent Pattern 的可疑性是通过计算它的 F1-Score 得出的。\n个人评论：CMDiagnostor 是清华大学裴丹老师的团队，话题是一个老话题，但是裴老师的团队又做出了新的创新点，不失为在没有 Trace 的情况下的一种解决方式吧。但是如果系统的 Trace 已经比较完善，应该是还是使用 Trace 能获得更准确的调用关系。\n 论文链接：https://netman.aiops.org/wp-content/uploads/2023/02/CMDiagnostor_www_2023.pdf 代码链接：https://github.com/NetManAIOps/CMDiagnostor\n  02 2023_WWW_CausIL: Causal Graph for Instance Level Microservice Data    论文简介: 论文为微服务系统提出一个服务实例级别（service instance level）的因果关系图构建框架 CausIL 。传统的因果构建图方式如 MicroHECL、Microscope 和上文的 CMDiagnostor 一般都是在服务级别（service level）构建因果关系图，这种构造方式对 instance level metric 进行聚合，可能会平滑了某个服务实例的异常表现。如下图两个例子都是在服务级别进行 metric 的 average 后导致了失真，从而影响到后面的根因定位。\n     为了克服在服务级别构建因果关系图的缺陷，本文就提出了构建服务实例级别的因果关系图。对于微服务S，设 x_ijt 是服务 S 的第 j 个实例在 t 时间的第 i 的指标，假设child metric x_ijt 是因果依赖于 parent metric 集合 P( x_ijt )，那给定 P( x_ijt ) 下， 图片的条件分布可以表示为:\n   因果关系估计算法的任务是识别每个 metric 的 parent metric P( x_ijt ) 以及因果函数 f_ij(.)。给定每个 child metric 的因果parent metric，通过估计器 f_ij(.) 估计 parent metric 和 child metric 之间的因果关系的强度。 CausIL 使用 Fast Greedy Equivalence Search（fGES）和 Bayesian Information Criterion (BIC) 进行因果发现\n   个人评论：这篇论文是 Adobe 印度研究院的团队发表的论文，最大的贡献是把因果关系细粒度化到服务实例级别，这么简单的 idea 我之前怎么没想到 。除此之外，论文里还融入了一些 domain knowledge，这些在工业界的实践值得参考\n在任何情况下，同一服务中的任何其他 metric 都不会影响 workload latency 不会影响 resource 利用率。 如果服务之间在调用图上没有连接，禁止服务之间的所有因果关联 对服务内部的 metric 之间的因果关系进行假设（如下图）\n    论文链接：https://arxiv.org/abs/2303.00554 代码链接：https://github.com/sarthak-chakraborty/CausIL\n 最后再来小结一下，今天我们分享了两篇在 WWW 2023 上有关因果关联的工作，在因果关联的这颗老树上又发出了新芽，而且这两篇论文，尤其是第二篇论文，都是有实际落地的可能，值得我们学习。\nCloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"5dd6c39bf0c0429d24b6100d9da912da","permalink":"https://yuxiaoba.github.io/post/www2023_1/","publishdate":"2023-03-21T00:00:00Z","relpermalink":"/post/www2023_1/","section":"post","summary":"国际互联网技术的研究与发展领域的顶级学术盛会 WWW 2023 即将开始，一起跟随本文追踪 WWW 2023 中云计算领域的最新研究吧～","tags":["Root Cause Analysis","Trace","AIOps"],"title":"最新出炉！WWW 2023 云计算领域论文盘点（一）","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今日雨水，小楼一夜听春雨，深巷明朝卖杏花。\n之前我在 基于 Traces 的根因定位（一）: Trace 的演进之路 简单地介绍了 Trace 的出现及其演进的过程。在 基于 Trace 的根因定位（二）： Spectrum-Based Fault Localization 算法 中介绍了基于 Spectrum-Based Fault Localization（SFL，基于程序频谱的故障定位）算法的 Trace 根因定位算法。​在 基于 Trace 的根因定位（三）：Trace 路径抽象 介绍了如何用路径抽象定位根因。\n这一期我们再来讨论一下另外一种基于 Trace 的根因定位算法：Trace 频繁模式挖掘。频繁模式，在 Trace 根因定位的背景下，可以理解为在一段时间内所有 Trace 中，出现频率较高的连续的 Span 集合。\n举个例子🌰，下图中有 5 条 Trace，\n   其中 (Span2 Span3) 可以视为在 Trace 集合中出现的模式（Pattern）。传统的频繁模式挖掘方法通常并不在意 Pattern 中的项的前后依赖关系，但是在 Trace 的分析中，我们应该只考虑那些连续的有父子关系的Pattern，如(Span2 Span3 Span4)， 而没有直接父子关系的 Pattern (Span2 Span4) 则不被考虑。\n这是因为 (Span2 Span4) 仅提供了 Span2 和 Span4 一起出现的证据，这个模式被破坏在根因定位中提供的作用较小。而 (Span2 Span3 Span4) 提供的是 Span2 调用了 Span3，且 Span3 调用了 Span4 的情况，如果这个模式被破坏则说明这个子调用链发生了问题，值得运维工程师关注。\n确定一个 Pattern 出现是否是频繁模式（Frequent Pattern），可以通过计算这个 Pattern 的支持度（support）来衡量。一种 Pattern 的 support 是指在所有 Trace 集合中这个 Pattern 出现的频率。如上图中 (Span2 Span3) 的 support 是 3 ，因为它一共出现了三次。 通常我们会定义一个最小支持度的阈值 Support_min 来进行划分。也就是说，如果一个 Pattern 的 support \u0026gt; Support_min, 那么判定这个 Pattern 属于 Frequent Pattern。\n在获得 Frequent Pattern 后，利用它们进行根因定位的核心思想是：对比正常 Trace 的频繁模式和异常 Trace 的频繁模式的差异，或者对比正常时间段 Trace 的频繁模式和异常时间段 Trace 的频繁模式的差异，找到只在异常时候发生，不在正常时候发生的频繁模式，从而将这些频繁模式判定为根因。\n这个思路是比较直观的且可解释的，如果一个 Pattern 在正常的时候经常发生，但是在异常的时候不发生了，那么很有可能这个 Pattern 是因为故障发生导致它没有按正常的路径运行，运维工程师应该优先检查这个 Pattern。或者如果一个Pattern 之前从不发生，但是在异常的时候发生频繁了，那么很有可能是故障的发生导致它变频繁，也应该优先检查这个 Pattern。而在正常阶段和异常阶段发生频率相似的模式，是不太需要关注的。\n下面我再简单介绍两篇使用频繁模式挖掘进行根因定位的论文。\n 01 21_ICSE_Scalable Statistical Root Cause Analysis on App Telemetry    论文简介: 论文提出了一个可扩展统计根因定位框架 Minesweeper。 Minesweeper 以没有故障的 Test 阶段的 Trace 和包含故障的 Control 阶段的 Trace 作为输入。 它首先通过 PrefixSpan 算法分别挖掘出 Test 和 Control 阶段的 Frequent Pattern 的 support 。\n   对每一个 Frequent Pattern P，Minesweeper 会根据下面的公式计算出它的 Precision 和 Recall\n   这里 Precision 描述了一个 P 在 Test 阶段出现，不在 Control 阶段出现的概率，也就是说在 T 中频繁出现，在 C 中出现不频繁的 P 可疑得分更高。Recall 描述了 P 能覆盖多少 Test 阶段的 Trace，它表示了 P 在 Test 阶段的代表性，越有代表性越重要。最后为了综合考虑两个参数，一个 Frequent Pattern 的可疑性是通过计算它的 F1-Score 得出的。\n个人评论：这篇论文是 Facebook 在 2021 年发表在 CCF A 类会议 ICSE 的 Industry Track 上的论文。Minesweeper 来自工业界的真实实践，使用简单的统计方法，可解释性比较强。不过论文似乎没有考虑并发和异步调用的情况。\n 论文链接：https://arxiv.org/abs/2010.09974\n  02 21_IWQoS_Practical Root Cause Localization for Microservice Systems via Trace Analysis    论文简介: 论文提出了一个 Spectrum 算法与频繁模式挖掘相结合的无监督根因定位算法 TraceRCA。TraceRCA 以一个时间窗口的 Trace 为输入，然后使用一个无监督多度量异常检测方法检测出异常的 Trace。Trace 异常检测是另外一个内容了，这里先不细说，我先挖个坑，以后再专门统一对 Trace 异常检测的论文进行分析。\n   在划分好正常的 Trace 和异常的 Trace后，TraceRCA 通过 FP-Growth 算法 来挖掘满足支持度阈值的 Frequent Pattern （即可疑的微服务集），然后计算出 Frequent Pattern 的支持度 (support )和置信度 (confidence) 。\n其中 support = P(X|Y)，X指的是通过某个 Pattern 的所有 Trace，Y是指所有异常的 Trace，这个 P 指的是在所有异常 Trace 中经过该 Pattern 的异常 Trace比例。 confidence = P(Y|X)，指的是所有经过该 Pattern 的 Trace中，异常 Trace所占的比例。\n接着 TraceRCA 计算他们的 Jaccard Index (JI) 得分，也就是 support 和 confidence 的调和平均数，获得 Pattern 的可疑得分。\n个人评论：论文是清华大学裴丹老师团队 2021 年发表在 CCF B 类会议 IWQoS 上的。与前面 Facebook 的方案比较大的不同是，TraceRCA 需要事先检测出异常的 Trace，这个 Trace 异常检测的效果会对后面根因定位的结果有较大的影响。并且对每条 Trace 进行准确异常检测，不仅难度比较大，计算的量也比较大，一定程度上限制了 TraceRCA 的使用。\n 论文链接：https://netman.aiops.org/wp-content/uploads/2021/05/1570705191.pdf 代码链接：https://github.com/NetManAIOps/TraceRCA\n 最后再来小结一下，与 Trace 路径抽象 中输出粗粒度的 Trace 路径不同，频繁模式挖掘最后输出的是一个更细粒度的路径子集，能够帮助运维工程师更快地聚焦到故障点。此外，基于统计的计算方式以及较强的可解释性，也为这种方法在工业界实际应用提供了可能。\nCloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1678060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678060800,"objectID":"08d35053d9addd1cbc5fde455f741fea","permalink":"https://yuxiaoba.github.io/post/trace_based_rca_4/","publishdate":"2023-03-06T00:00:00Z","relpermalink":"/post/trace_based_rca_4/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Trace 记录了请求在分布式应用程序中运行的轨迹，能够完整的串联起请求的上下文关系，在大规模分布式系统根因定位中的作用举足轻重。阅读本文可快速了解当前学术界热门的基于 Trace 的根因定位算法类型 —— Trace 频繁模式挖掘 。","tags":["Root Cause Analysis","Trace"],"title":"基于 Trace 的根因定位（四）：Trace 频繁模式挖掘","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今日雨水，小楼一夜听春雨，深巷明朝卖杏花。\n之前我在 基于 Traces 的根因定位（一）: Trace 的演进之路 简单地介绍了 Trace 的出现及其演进的过程。在 基于 Trace 的根因定位（二）： Spectrum-Based Fault Localization 算法 中介绍了基于 Spectrum-Based Fault Localization（SFL，基于程序频谱的故障定位）算法的 Trace 根因定位算法。​\n这一期我们再来讨论一下另外一种基于 Trace 的根因定位算法：Trace 路径抽象。\n路径（Path）是请求在系统中运行路径的抽象，它记录了同一类请求经过的组件的性能和交互关系。\n例如对于五个 Trace： a → b → c → d\na → e → f\na → b → c → d\na → e → f\na → e → f\n我们可以将其抽象为两个 Path： a → b → c → d\na → e →f\n然后可以通过统计分析，计算每个组件的平均延迟。\n基于 Trace 路径抽象进行根因定位的核心思想是：如果我们预先对没有故障的（fault-free）阶段的 Trace 进行 Path 的抽象，那么在故障发生（fault-suffering）阶段我们可以通过比对当前时间窗口的 Path 与历史的 Path 是否表现一致来检测异常和定位根因。\n 01 04_NSDI_Path-Based Failure and Evolution Management    论文简介: 论文以 Trace 作为输入，在根因定位时主要分为两个步骤：\n第一步首先是检测哪些 Path 表现异常，其中包括结构异常和性能异常\n  对结构异常，论文首先通过 probabilistic context free grammar (PCFG) 根据训练过程中 的 fault-free data 抽象出 Path，并对给定 Path 发生的可能性进行建模。在生产阶段，如果抽象出来的 Path 不符合训练的 PCFG 模型，那么认为这个 Path 的结构是异常的\n  对性能异常，系统延迟的偏差往往是问题的信号。尾延迟的增加可能表明部分故障，而平均延迟的增加可能表明过载。延迟的减少可能是由于错误造成的阻止一个请求执行完成\n  第二步是定位根因，其中包括只有一种 Path 异常和多种 Path 异常发生的情况\n  对只有一种 Path 异常，论文通过 Path 所体现的控制流引导着本地日志分析工具的使用，以将组件的细节与特定的请求联系起来。如果没有 Path ，单个组件的日志就不那么有用了，因为缺乏日志条目和其他系统状态之间的关联\n  对多种 Path 异常的情况，其核心思想是搜索组件的使用和失败的请求之间的相关性。论文通过训练一个决策树模型来区分成功和失败的类别，其中导致失败的树边成为根因的候选\n     下图展示了论文的可视化界面\n   个人评论：论文来自 UC Berkeley David Patterson 的 20 年前发表在 NSDI （CCF A）的古董论文，对 Trace 已经有很深刻的见解，并且已经尝试使用 log 和 trace 的融合进行根因定位。20 年后的 Trace 分析方法也没有能逃出这个分析框架，只能说 RiseLab YYDS。\n 论文链接：https://www.usenix.org/conference/nsdi-04/path-based-failure-and-evolution-management\n  02 20_FSE_Graph-Based Trace Analysis for Microservice Architecture Understanding and Problem Diagnosis    论文简介: 论文提出一种基于图形分析的微服务架构理解和问题诊断方法 GMTA。GMTA 将微服务中的 Trace 转换为Graph ，通过 Graph 的分析和可视化来发现微服务架构中的问题和瓶颈。它主要提供了四种 Graph 的展示方式：Trace, Path, BusinessFlow 和 Error Propagation Chains （EP Chains）\n    Trace：GMTA 根据 Trace ID 对同一个请求的 Span 进行聚合，然后对一些缺乏 Root Span 和没有 Parent span 的 Trace 进行了修复 Error Propagation Chains：给定一个带有 error attribute 的 Span，GMTA 检查该 Span 的一个Child Span 是否也有错误标记，从而构建出 EP Chains Path: 对每一条 Trace，GMTA 根据 Trace 访问的微服务名称和操作名称进行哈希，生成 Path ID。如果 Path ID 已经存在，那么更新 Path 的属性（如trace数、平均延迟等）。如果 Path 不存在，便为这条 Trace创建一个新 Path。 Business Flow: 由运维人员按需求制定的调用某个微服务与当前操作之前/之后会调用某个微服务 的任意组合。  最后 GMTA Explorer提供4类主要功能。前面两个可视化相关功能主要用于系统架构理解、后面两个功能主要用于故障诊断。下面是可视化的几个样例。\n      个人评论：论文是 eBay 与复旦大学彭鑫老师团队合作发表的论文。论文更多的是针对于 Path 的抽象和可视化的展示，对根因定位的自动化考虑的还是比较少。\n 论文链接：https://taoxie.cs.illinois.edu/publications/esecfse20in-trace.pdf\n 从 2004 年到 2020 年，16 年的时间里可观测性有了很大的发展，分布式的场景让 Trace 已经走进千家万户。现在大型互联网厂商每日产生的 Trace 数目上百亿条，手动地分析和查看单条 Trace 越来越不实际。对同种类型的 Trace 的路径进行抽象，再具象化，能够更直观地反映当前某种请求的处理状态，降低运维工程师的运维压力。但目前基于 Trace 路径抽象方法的根因定位大多还是 UI 展示功能，根因定位自动化能力不足，未来还需继续研究。\nCloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1676678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676678400,"objectID":"5881dab56cd3465731f9650e12a8a0df","permalink":"https://yuxiaoba.github.io/post/trace_based_rca_3/","publishdate":"2023-02-18T00:00:00Z","relpermalink":"/post/trace_based_rca_3/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Trace 记录了请求在分布式应用程序中运行的轨迹，能够完整的串联起请求的上下文关系，在大规模分布式系统根因定位中的作用举足轻重。阅读本文可快速了解当前学术界热门的基于 Trace 的根因定位算法类型 —— Trace 路径抽象。","tags":["Root Cause Analysis","Trace"],"title":"基于 Trace 的根因定位（三）：Trace 路径抽象","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今日立春，东风吹散梅梢雪，一夜挽回天下春。\n之前我在 基于 Traces 的根因定位（一）: Trace 的演进之路 简单地介绍了 Trace 的出现及其演进的过程。下面我将总结第一种基于 Trace 的根因定位算法：基于 Spectrum-Based Fault Localization（SFL，基于程序频谱的故障定位）算法的 Trace 根因定位算法。​\n首先我们介绍一下什么是 SFL ？\nSFL 是软件测试领域定位故障常用的一种方法。该方法通过测试用例对被测函数（代码实体）的覆盖情况以及测试用例成功或失败来对潜在的代码错误进行定位。\n具体地，对于某个函数 𝑓 ， 𝑒𝑝 为覆盖了该函数并成功运行的测试用例的数量， 𝑒𝑓 为覆盖了该函数但运行失败测试用例的数量， 𝑛𝑝 为未覆盖该函数并成功运行的测试用例的数量， 𝑛𝑓 为未覆盖该函数并运行失败测试用例的数量。最后通过一些数学公式，利用这四个原始统计量计算各个函数的得分。\n如下图是一个由 3 个被测函数和 4 个测试用例的示意图，其中函数 m2 存在代码错误，而且是条件触发的，所有标红的函数和测试用例都出现了错误。下表中给出了不同函数的 SFL 原始统计量的取值。\n   根据数学推理和证明，已经有许多 SFL 计算公式，如\n   根据 Tarantula 计算方式，上图中 m1、m2、m3 的SBFL的得分分别为 0.5、0.57 和 0，显示代码错误发生在 m2。\n   我们通过上面的例子可以观察到，每条测试用例经过的程序路径，与 Trace 在分布式系统中的运行路径是相似的\n由此我们尝试将 SFL 应用到 Trace 的根因定位中，下面我简单介绍一下我们在这方面的工作。\n 01 21_CCGrid_T-Rank:A Lightweight Spectrum based Fault Localization Approach for Microservice Systems    论文简介: T-Rank 将微服务的 Trace 作为输入，首先根据 Trace 经过的服务实例的次数对 Trace 进行分类。接着对每个类别的 Trace，Anomly Detector 通过对 3-sgima 找到该类别中请求延迟异常的 Trace 并判定为异常 Trace，其他 Trace 则归为正常 Trace。最后根据 表 1 的对应关系，将异常 Trace 和 正常 Trace 输入到 SFL 计算公式中得出最后的根因。\n    论文链接：https://yuxiaoba.github.io/publication/trank/trank.pdf\n  02 21_WWW_MicroRank: End-to-End Latency Issue Localization with Extended Spectrum Analysis in Microservice Environments    论文简介: 经过更深的研究，像 T-Rank 这样将 Trace 数据简单地输入到 SFL 中只考虑了 Trace 的覆盖信息，没有考虑 Trace 它所携带的服务依赖信息，导致无法处理一些 SFL 得分相同的情况。 因此我们提出了能够将服务依赖信息也融入进 SFL 计算的 MicroRank 根因定位框架。\n   与 T-Rank 类似的，MicroRank 首先根据 Trace 的延迟将 Trace 划分为异常 Trace 和 正常 Trace。然后 MicroRank 根据正常和异常 Trace 分别构建出正常，异常 operation-trace 图，并在这两个图上利用 PageRank 算法计算出每个 operation 的正常和异常的权重。最后，MicroRank 基于权重与覆盖统计信息相乘的结果计算 SFL 来得到根因。\n个人评论：这两篇论文都是我自己写的，所以可以不需要顾忌，可以直接光明正大的嫌弃自己。基于 SFL 的 Trace 根因定位算法，从思想上是非常容易理解的，但是在实际应用中还是存在几个问题：\n  基于 SFL 的 Trace 根因定位算法非常依赖于正常和异常 Trace 的判断结果，但是想要很好地判断哪些 Trace 是正常，哪些 Trace 是异常，其实并不容易。我们不仅需要考虑 Trace 的延迟，还需要考虑 Trace 的返回码， Trace 的结构等等。一旦正常和异常 Trace 判定错了，也会影响到方法的准确率。\n  基于 SFL 的 Trace 根因定位算法非常依赖于 Trace 的质量，如果 Trace 的质量比较差，有很多的莫名其妙的断链，实际用起来准确率也会大打折扣。\n  基于 SFL 的 Trace 根因定位算法目前更倾向于去解决 Microservice 的性能问题，而不是可用性问题，在可用性问题上还需要进一步讨论。\n   论文链接：https://yuxiaoba.github.io/publication/microrank/microrank.pdf\n 以上我简单介绍了基于 SFL 的 Trace 根因定位算法的思路，相对来说，这种基于统计的根因定位方法比基于深度学习的方法，更容易让运维工程师理解，可解释性也更强。但是要实际地落地，还需要进一步的研究，希望未来我们还会在这个领域有更大的进展。\nCloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1675468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675468800,"objectID":"43919873b0b56b76236bd656b163d7fd","permalink":"https://yuxiaoba.github.io/post/trace_based_rca_2/","publishdate":"2023-02-04T00:00:00Z","relpermalink":"/post/trace_based_rca_2/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Trace 记录了请求在分布式应用程序中运行的轨迹，能够完整的串联起请求的上下文关系，在大规模分布式系统根因定位中的作用举足轻重 。阅读本文可快速了解当前学术界热门的基于 Trace 的根因定位算法类型——Spectrum-Based Fault Localization  算法。","tags":["Root Cause Analysis","Trace"],"title":"基于 Trace 的根因定位（二）： Spectrum-Based Fault Localization  算法","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今日小寒，小寒纪节欣相遇，瑞兆占年定可期。\nACM Symposium on Cloud Computing 是 Cloud Computing 领域的顶级会议。SoCC 虽然是一个 CCF B 会议，但它是我最喜欢的计算机会议，而且我觉得 SoCC 的 Paper 是有 A 类会议实力的。很遗憾它这次没有像 Eurosys 一样增补为 A 类会议。\nSoCC 2022 会议共收到 155 份投稿，录用了 38 篇，录用率 24.5% 。作为 SoCC 的忠实粉丝，当然我也投了，当然我也是分母。之前我分享和推荐了部分 SoCC 2022上我很感兴趣的论文 SoCC 2022 论文集合（一），这一次我们继续介绍两篇 SoCC 2022 上的 Paper。\n 01 22_SoCC_DeepScaling: Microservices AutoScaling for Stable CPU Utilization in Large Scale Cloud Systems    论文简介: 为了在保障服务 SLO 的前提下，使系统的 CPU 利用率最大化从而减少资源的消耗，蚂蚁金服提出了一个名为 DeepScaling 的微服务自动伸缩框架。DeepScaling 将微服务自动伸缩3个模块：流量预测模型（Workload Forecaster），CPU估计模型（CPU Utilization Estimator）以及容量决策模型（Scaling Decider）。\n DeepScaling使用 Spatio-temporal Graph Neural Network 预测每个微服务的 Workload DeepScaling通过使用 Deep Neural Network, 将工作负载强度（包括RPC请求、文件I/O、DB 访问、消息请求、HTTP请求，以及特定的辅助特征如实例数、服务ID、时间戳等）映射到估计的 CPU 利用率来估计 CPU 利用率 DeepScaling 基于改进的 DQN 强化学习算法为每个服务生成自动缩放策略     个人评论： DeepScaling 与 SoCC 2022 论文集合（一） 中的叶可江老师的 paper 的思路是类似的。DeepScaling 在蚂蚁集团拥有135个微服务的真实生产环境中部署，平均每天可节省3 W多个CPU内核, 6W 多GB的内存。虽然 DeepScaling 被小范围应用，但是我个人感觉如果工作负载预测准了，后面应该无需加上这么复杂的服务实例决策方法，也没有必要使用黑盒的方法。\n 论文链接：https://dl.acm.org/doi/pdf/10.1145/3542929.3563469\n  02 22_SoCC_Method Overloading the Circuit    论文简介: Circuit Breaker (中文被翻译成熔断或者断路器) 机制是应对雪崩效应的一种微服务容错机制。当链路的某个微服务出错不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。\n论文研究了两个来自大型食品配送平台 DoorDash 的 Circuit Breaker 工业使用案例。论文发现，现有的 Circuit Breaker 设计不仅不足以容错，而且还发现了应用程序代码中的小变化会对 Circuit Breaker 的工作方式有很大的改变。为了解决这些缺陷，论文提出了两种新的 Circuit Breaker 设计：Path-sensitivity 和 Context-Sensitivity 的 Circuit Breaker，并设想了它们的实现方式。\n   个人评论： 论文的角度很新奇，从 Circuit Breaker 的角度出发，是之前很少学术论文考虑的，比起一些做烂的话题，这个也挺有意思的。这个 CMU 的作者 Christopher Meiklejohn 也是一个牛人，一边创业一边发 Paper, 着实羡慕。\n 论文链接：https://dl.acm.org/doi/abs/10.1145/3542929.3563466\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1672790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672790400,"objectID":"3d78075f581386404ae42453f2aed8ec","permalink":"https://yuxiaoba.github.io/post/socc_2/","publishdate":"2023-01-04T00:00:00Z","relpermalink":"/post/socc_2/","section":"post","summary":"ACM Symposium on Cloud Computing 是 Cloud Computing 领域顶级的会议。SoCC 2022 上周在旧金山举行，会议共收到 155 份投稿，录用了 38 篇，本文想要分享一下 SoCC 上我很感兴趣的部分论文。","tags":["Cloud Computing"],"title":"SoCC 2022 论文集合（二)","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"之前我总结了两种常见的基于 Metric 的根因定位算法 基于 Metrics 的根因定位 (一)：故障刻画 和 基于 Metrics 的根因定位 (二)：因果关系图 。这一次介绍第三种基于 Metric 的根因定位算法: 多维下钻。\n在 SRE 检测到 KPI 发生异常时（如响应成功率下降），还面临一个灵魂拷问：为什么发生异常了？（成功率为什么下降了？），这个时候我们需要增加维的层次，从而可以由粗粒度的数据到细粒度的数据来观察数据。\n例如下表我们发现某服务的当前总的失败请求数目比前一个时间点增加了很多，工程师会进一步挖掘失败请求的属性，比如查看数据中心的元素，发现广州的数据中心存在异常导致的这次故障，这就是一个简单的多维下钻的样例。\n   数据中心 前一时间点失败请求数 当前时间失败请求数 差异     广州 10 1000 990   上海 5 5    北京 10 11 1   合计 25 1016 991     01 14_NSDI_Adtributor: Revenue Debugging in Advertising Systems    论文简介: 论文针对广告营收领域的 revenue debugging问题，将多维根因分析问题分解为多个单维根因分析问题，提出了的 Adtributor 算法，并分别针对量值与率值两类指标进行多维度的根因分析。整体思路如下：\n  利用 ARMA 模型进行异常检测。根据8周的历史数据，考虑到正常的时间和星期的波动，生成一个基于模型的测量值预测。然后，将实际值与预测值进行比较：当一个测量值的实际值与预测值有明显差异时，将产生一个异常警报。\n  计算每个维度下每个元素的 explanatory power （单个元素预测值与实际值的差异和整个维度预测值与实际值差异的比值，论文公式 4） 与 surprise 值（可直观理解为预测值与实际值变化的程度，论文公式 5），定位出每个维度下的异常元素集合，最后根据每个维度总的 surprise 值大小汇总输出根因集合。\n     个人评论： Microsoft 2014 年发表在 NSDI （CCF A）上的论文，论文可以说是基于 Metrics 的多维下钻分析的开山之作，论文在 Mcirosoft 实际落地，可解释性比较强，后面的多维下钻的工作也大多在其基础之上进行创新。\n 论文链接：https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-bhagwan.pdf\n  02 16_ICSE_iDice: Problem Identification for Emerging Issues    论文简介: 软件在发布时一般会有很多分类属性（例如版本号，地域，操作平台等），如果发布有异常，用户通过会上报一些反馈的 Issue，此时需要运维工程师能够快速定位究竟是哪些属性造成了 Issue 的上升，提升响应的速度。文章以 Issue 的上升作为告警，通过分析一个时间窗口内 Issue 的属性的组合，找出最有可能导致 Issue 上升的最小属性组合。在搜索空间过大的问题上论文使用了启发式的三个剪枝策略来应对：\n  Impact based Pruning：一个有用的属性必须引起较大数量变化\n  Change Detection based Pruning: 一个有用的属性组合必须在时间点上符合变化特征\n  Isolation Power based Prunning: 合并多余属性组合\n     个人评论： MSRA 林庆维研究员 2016 年发表在 ICSE（CCF A）的论文。论文针对性地处理了用户反馈 Issue 的维度下钻，并在微软落地，剪枝的策略值得学习。\n 论文链接：http://hongyujohn.github.io/iDice.pdf\n  03 20_ASE_ImpAPTr: A Tool For Identifying The Clues To Online Service Anomalies    论文简介: 论文是一个广度优先的多维下钻根因定位算法，ImpAPTr，整体思路可分为以下四个步骤：\n  根据维度组合创建包含根结点和子结点的元素树，如下图所示；\n  采用广度优先遍历算法，删除冗余元素和影响系数 （Impact Factor）相反的元素（论文公式3）；\n  计算每个维度组合的贡献度 （Contribution Power，连续两个时间段的影响系数差值，论文公式4）和差异系数 （Diversity Factor， 两个连续时间段内的成功率指标变化程度， 论文公式 5） ；\n  计算每个维度组合 Contribution Power 和 Diversity Factor 的排名之和 ，选取前 n 个维度组合作为成功率下跌的根因线索。\n     个人评论： 论文是南京大学与美团合作发表在 ASE 2020 上的一篇短文。与 Adtributor 只考虑单个维度不同，ImpAPTr 考虑了多个维度，且构建出维度之间的关系图，通过在图上做广度优先搜索进行根因定位。美团实际落地算法的总结。方法在根因的属性数量不多以及单根因的时候效果应该会比较好。\n 论文链接：https://dl.acm.org/doi/10.1145/3324884.3415301\n代码链接：https://github.com/wanghaoUp/ImpAPTr\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1671580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671580800,"objectID":"a635c79b5f059a2d2080039391606d42","permalink":"https://yuxiaoba.github.io/post/metric_based_rca_4/","publishdate":"2022-12-21T00:00:00Z","relpermalink":"/post/metric_based_rca_4/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Metrics 又是三者中在根因定位中最常用的数据源，阅读本文可快速了解当前学术界热门的基于 Metric 的根因定位算法类型——多维下钻。","tags":["Root Cause Analysis","Metrics"],"title":"基于 Metrics 的根因定位 (四)：Meanful Metrics","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今日冬至，天时人事日相催，冬至阳生春又来。\n2022 年 5 月我入选了 2022 腾讯犀牛鸟精英人才计划，来到微信的技术架构部的质量平台组做科研实习生。在降本增效的大背景下，我到微信的第一个研究工作是降低海量日志打印和存储的开销。 基于该研究的论文 “ LogReducer: Identify and Reduce Log Hotspots in Kernel on the Fly ” 被软件工程领域顶级国际会议 ICSE 2023 的 Technical Track 录用。论文作者包括中山大学的余广坝、陈鹏飞，腾讯的李派锐、翁天俊、郑海兵，邓月堂。\n 1. 研究问题 为了协助工程师及时地发现和诊断软件运行时的发生的故障，工程师通常会在程序代码中插入日志语句打印软件运行时的状态。但是，虽然打印大量的运行时日志对定位和解决故障很有帮助，但是日志打印不仅会影响到软件运行的性能，而且造成了很大的持久化负担。在微信，每天的后台日志打印接近 100 万亿行，占用了接近 20 PB 的存储，带来了巨大的运营成本。\n   为了削减日志的运营成本，我们对微信后台的日志打印和存储的特征进行了分析和挖掘，我们发现「绝大多数的日志开销是由少数的几条日志语句导致的」，我们将这些日志语句称为「日志热点」。这个发现启发我们：「及时发现日志热点，对日志热点的打印进行优化即可降低大量的日志开销」。 例如，微信某个服务的占用存储 Top1 的日志模板占用了该服务 95.7% 的存储，而其他200多个日志模板只占用了剩余 4.3% 的存储，因此如果我们能把 Top1 的这条日志进行优化（如采样或者合并打印）就可以降低大量的开销。\n但是，即便是我们通过分析存储发现了日志热点，想要对其进行及时的处理也不容易。在运营工程师发现某个服务的日志热点并告警给服务对应的开发工程师时，考虑到服务更新上线的计划，开发工程师一般不会立即对日志热点进行优化并上线，通常是等待到服务的下一次更新才进行上线。即便是程序上线后，灰度发布的过程也可能会持续几个小时甚至几天才能更新完服务的所有实例。在这期间，日志热点还是会持续影响程序。 因此我们必须能够在程序运行时对日志热点进行优化。「我们需要一个能够在运行时对日志打印进行针对性拦截和优化的工具，用于缓解发现日志热点到服务上线完成期间的日志开销」。\n 2. 日志热点的实证研究 为了更好地理解日志热点，我们首先对微信的日志热点做了一些实证研究。\n日志热点定义 首先我们对日志热点进行定义：假设一个服务 A 在一个时间窗口内占用了S GB 存储， 它包含 n 个日志模板:log1,log2,…,logn, 这些日志模板分别占据了S1,S2,….,Sn GB 的存储 (其中S =S1+S2+…+Sn)，那么日志热点可以定义为：\nSi/S\u0026gt;ξ,\n这里的 ξ 由工程师制定，我们默认为 0.05。\n日志热点的普遍性 我们选取了微信后台日志中存储占用前 20 的服务，对其日志存储进行分析，我们发现日志存储占用前 20 的服务占用了超过 50 % 的存储空间，而其他剩余的 20000 多个服务才占用了 47.2% 的存储空间。\n   我们对上述20个服务的所有日志模板进行逐一的分析，我们发现其中有 19个服务至少包含一个日志热点。日志热点的存储总和平均占对应服务存储的 57.86%。\n    日志热点在不同的服务中普遍存在。对日志热点进行优化是一个性价比很高的日志约简操作。\n 日志热点对应用性能的影响 为了分析日志热点对性能的影响，我们对只更新了优化日志热点代码的服务的前后版本性能表现进行对比，我们发现，在相似的工作负载情况下，存在日志热点的版本要比不存在日志热点的版本多消耗 5% 的 CPU （58个核心） 和额外增加 3% 的延迟 （1.8ms）。\n    日志热点打印会造成额外的资源消耗（例如，CPU、内存）和性能下降。优化日志热点打印不仅减少了应用程序的资源消耗，还能提高了其性能。\n 日志热点修复的时长 当我们将日志热点告警给开发工程师后，我们持续跟踪日志打印和工程师优化上线的情况，对日志热点出现到被优化的时间进行了统计。我们发现 97% 的日志热点都是在告警3天以后才得到优化，平均需要超过 9 天。\n   同时我们还发现，日志热点的优化并不是一次性的工作，随着程序的迭代，新的日志热点会持续的出现。我们持续观察这 19 个服务三个月，发现 18个服务在优化后再次出现了热点日志。\n    日志热点优化通常不能得到及时的响应，且服务会反复出现日志热点。在生产环境中自动检测和运行时动态地修复日志热点是非常重要的。\n 此外我们还对日志热点出现的原因和修复方式进行了调研，详细内容可以看我们的论文。\n 3. LogReducer 日志约简框架 对微信这种体量的用户，想要设计一个高效的能够在生产环境中自动检测和运行时动态地修复日志热点的工具是很有挑战的：\n 「海量的日志规模」：每天需处理上百亿行日志，框架处理日志必须足够高效 「不影响程序开发」：框架对开发工程师是无感知的，不需对原有代码进行修改或者重编译 「支持多种编程语言」：框架应该能够支持对多种编程语言的日志打印进行优化 「不影响服务运行」：框架的执行应该不影响服务的正常运行，不能重启或中断服务  传统的日志压缩方法虽然可以缓解日志存储的压力，但是无法消除日志打印对运行时的影响以及日志发送到数据库的开销。在 log agent（例如：filebeat, promtail）中对热点日志进行过滤也是一种解决方式，但是它同样无法消除日志打印对运行时的影响，而且过滤的效率较低。 为了更好的解决上面的挑战，我们提出了一个「基于 eBPF 的日志约简框架：LogReducer」，框架图如下图所示：\n   LogReducer 的运行工作流如下所示：\n① LogParser 周期性地从日志数据库中拉取数据，然后基于日志框架中打印的代码位置解析出日志模板，并统计出每个日志模板对应的存储消耗。\n② Hotspot Classifier 根据日志热点定义的公式判定是否存在日志热点。\n③ 如果存在日志热点，Hotspot Classifier 会将日志热点的模板及存储占用信息分别告警离线阶段的程序员和在线阶段的 Log Filter 中。程序员在收到告警后，会根据经验对日志热点进行修复和重新发布。\n④ 在在线阶段，在用户态的 Python Log Filter 会根据告警的日志模板信息，将模板信息 load 进 eBPF Maps 中。在内核态的 eBPF Log Filter 会实时拦截和解析应用程序调用系统调用 Write() 写日志的操作，并在内核态将写入的日志与 eBPF maps 中的日志模板进行匹配，如果匹配成功，则将该次写入丢弃，提前返回日志写入操作，避免日志的用户态和内核态切换，也避免了实际的写入操作。\n 4. 实验评估 为了评估我们提出的框架，在在线阶段，我们用四种不同的编程语言写了四个日志打印的 benchmark，然后通过控制每秒打印的日志数目测试 LogReducer 的消耗。从下图可以看出，LogReducer 在每个服务实例每秒打印 10 万条日志的时候，也只会给「每个请求增加 500 纳秒」 (一纳秒等于一秒的十亿分之一)的延迟，消耗的 CPU 资源也不到单核的万分之一。\n   在离线阶段，我们将告警转发到企业微信并自动拉群，将日志热点的信息转发给服务对应的开发工程师，由开发工程师对日志进行优化。离线阶段的方法在微信实际落地后，将微信每日日志存储量从「20 PB 降低到 12 PB （每日日志存储量降低了40%，每年节省上千万人民币)」。\n   以上就是论文的主要内容了，因为最近有点忙，camera-ready 的论文我还没有准备后，后面准备好我会尽快将论文上传到我的个人主页（https://yuxiaoba.github.io）和 Github 的仓库（https://github.com/IntelligentDDS/awesome-papers），欢迎关注我们的工作！。\n最后，非常感谢微信的 Perry, Matt 哥，Tang 哥，还有参与 emparical study 的各位大佬们对论文的支持。第一次离开实验室，来到工业界下山游历，做的还是自己不太擅长的日志分析，说实话是有点慌的，还好一路得到好多人的帮助，也希望后面还会有其他的产出。\n2022 年只剩下 10 天了，本文应该是 2022 年我们的最后一篇推送，感谢大家对我们实验室工作的关注。特殊时期，愿大家各自保重，祝各位身体安康，一起迎接 2023 年的到来！\nCloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1671494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671667200,"objectID":"fee5a0aef373e523750b0b4a2a7efbdc","permalink":"https://yuxiaoba.github.io/post/recent_paper2/","publishdate":"2022-12-20T00:00:00Z","relpermalink":"/post/recent_paper2/","section":"post","summary":"与微信合作的第一作者论文 LogReducer Identify and Reduce Log Hotspots in Kernel on the Fly 被软件工程领域顶级国际会议 ICSE 2023 的 Technical Track 录用","tags":["Cloud Computing","eBPF","Log"],"title":"DDS 第一手研究曝光：基于 eBPF 的日志热点约简框架","type":"post"},{"authors":["Guangba Yu","Pengfei Chen","Pairui Li","Tianjun Weng","Haibing Zheng","Yuetang Deng","Zibin Zheng"],"categories":null,"content":"The blow figure shows the framework of LogReducer.   ","date":1670544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670544000,"objectID":"68d51060464a56deb51c4188c2964bea","permalink":"https://yuxiaoba.github.io/publication/logreducer22/","publishdate":"2022-12-09T00:00:00Z","relpermalink":"/publication/logreducer22/","section":"publication","summary":"In this paper, we propose LogReducer, a non-intrusive and language-independent log reduction framework based on eBPF (Extended Berkeley Packet Filter), consisting of both online and offline processes. After two months of serving the offline process of LogReducer in WeChat, the log storage overhead has dropped from 19.7 PB per day to 12.0 PB (i.e., about a 39.08% decrease).","tags":["Log","eBPF","Telemetry"],"title":"LogReducer: Identify and Reduce Log Hotspots in Kernel on the Fly","type":"publication"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今日小雪，枫叶欲残看愈好，梅花未动意先香。记得加衣服了～\nACM Symposium on Cloud Computing 是 Cloud Computing 领域顶级的会议。SoCC 虽然是一个 CCF B 会议，但它是我最喜欢的计算机会议，而且我觉得 SoCC 与 Eurosys 的 Paper 都是有 A 类会议实力的。\nSoCC 2022 上周在旧金山举行，会议共收到 155 份投稿，录用了 38 篇，录用率 24.5% 。作为 SoCC 的忠实粉丝，当然我也投了，当然我也是分母。不过今天还是想要分享和推荐 SoCC 2022 上我很感兴趣的部分论文。\n 01 22_SoCC_How to Fight Production Incidents? An Empirical Study on a Large-scale Cloud Service    论文简介: 论文从 incident 的生命周期（即 root cause、detection、mitigation ）的角度分析了 Microsoft Team 从 2021 年 5 月到 2022 年 5 月发生的 152 个较为严重的 incident，并对每个阶段之间的相关性进行了详细的分析。回答了以下四个问题：\n  为什么会发生这些 Incident\n  如何修复这些 Incident ?\n  什么原因导致检测和修复 Incident 需要较长延迟？\n  什么样的自动化可以帮助服务恢复可用性?\n        个人评论： 论文是来自 Microsoft ，获得了今年 SoCC 的 Best paper ! 在 DDS 第一手研究曝光（一） 介绍了今年我们在 ISSRE 2022 的分析 Incident 的论文，无独有偶，论文角度几乎一致，但本文作者在企业内部，有更详细的数据，能分析的细节更多。\n 论文链接：https://dl.acm.org/doi/10.1145/3542929.3563482\n  02 22_SoCC_SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management    论文简介: Serverless FaaS 被誉为下一代的云计算范式，它提供了尽可能小粒度的资源分配和极致的弹性。但如此细粒度的情况下，在保持高资源利用率的同时管理资源以满足SLO的问题是一个 NP-hard 的问题。论文首先讨论了基于 Single-agent RL 的框架无法感知函数之间的动态资源竞争，会导致延迟不稳定从而违背 SLO。\n   因此， SIMPPO 采用了 Multi-agent RL 框架，它为每个函数配置了一个 Agent 以获得 FaaS 函数的最优资源配置（CPU Limit, Memory Limit, Number Limit）。在训练阶段， SIMPPO 的核心思想是将其他函数和环境的 Multi-agent 视为一个 “Virtual Agent\u0026#34;，将 Multi-agent 转化成为了一个 Two agent 的问题，从而大大加快了强化学习模型收敛的速度。\n   个人评论： 论文是来自 UIUC 的 Qiu Haoran 博士，也是之前 OSDI 2020 的微服务自动伸缩 FIRM 的作者，也是我的直接竞争者，跟 UIUC 的大佬在这么小的方向撞车真的太难受了。论文在为函数训练模型时是没有考虑函数的参数的，应该来说比较难适应参数变化的问题，也没有考虑函数链的情况。论文还采用了一种两段式的论文写作方式，推荐可以去看看学习学习。\n 论文链接：https://haoran-qiu.com/pdf/socc22.pdf\n  03 22_SoCC_The Power of Prediction: Microservice Auto Scaling via Workload Learning    论文简介: 论文首先基于两个观察：1）单个微服务的 Workload 存在较大的不确定性；2）每个 Container 的 Workload 与 OS-level metrics 存在很强的相关性，提出为每个微服务训练一个自动伸缩的模型来满足 SLO。在离线阶段，论文首先训练出一个融合了 Stochastic Attention 机制的 Seq2Seq 模型对 Workload 进行预测，然后基于 Linear Regression 学习出 CPU 和 Memory 跟 Workload 之间的关系。在线阶段，论文通过预测 Workload 找到可以满足 CPU 和 Memory 的最小服务实例数目，从而执行 Autoscale 。\n   个人评论： 论文是去年的 SoCC Best Paper 叶可江老师团队再一次与阿里巴巴合作的基于 Trace 的成果，每年都有一篇 SoCC 可太羡慕了。利用 Trace 精确为每个服务进行 Autoscale 是一直我想做的，思路也是一致的，叶老师做的太快了.\n 论文链接：https://dl.acm.org/doi/abs/10.1145/3542929.3563477\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1668902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669075200,"objectID":"e82e99c83f849f122e48c91f97d7f0b9","permalink":"https://yuxiaoba.github.io/post/socc_1/","publishdate":"2022-11-20T00:00:00Z","relpermalink":"/post/socc_1/","section":"post","summary":"ACM Symposium on Cloud Computing 是 Cloud Computing 领域顶级的会议。SoCC 2022 上周在旧金山举行，会议共收到 155 份投稿，录用了 38 篇，本文想要分享一下 SoCC 上我很感兴趣的部分论文。","tags":["Cloud Computing"],"title":"SoCC 2022 论文集合（一)","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"今日立冬，细雨生寒未有霜，庭前木叶半青黄。\nMetrics, Traces, Logs 被誉为可观测性的三大支柱，先前我总结了基于 Metric 的三种根因定位方法：\n 基于 Metrics 的根因定位 (一)：故障刻画 基于 Metrics 的根因定位 (二)：因果关系图 基于 Metrics 的根因定位 (三)：多维下钻  接下来的几个月里，将继续不定期总结基于 Trace 的根因定位方法。Trace 追踪了请求在应用程序中运行的轨迹，能够完整的串联起请求的上下文关系，在大规模分布式系统根因定位中的作用举足轻重 。在讨论基于 Trace 的根因定位之前，本文先简单介绍 Trace 的出现及其演进的过程。\n 01 02_DSN_Pinpoint: Problem Determination in Large, Dynamic Internet Services    论文简介: 典型的 Internet 服务有许多分为多个层的组件：Frontend、WebServer 和 Database，每个层中的许多（复制的）子组件。当客户端连接到这些服务时，它们的请求将通过该系统动态路由到子组件。为了捕获这些动态的请求路径，Pinpoint 设计了一种记录每个请求经过组件的数据格式，用于帮助工程师分析根因。\nPinpoint 为每个组件（Component）生成唯一的 Component ID 用于标记组件，为每个 HTTP 请求生成唯一的标识 Request ID 标记请求。在请求执行中 Request ID 通过线程局部变量（ThreadLocal）传递到下游组件，每次调用到一个组件，就使用 (Request ID , Component ID) 组合记录一个 Trace Log。除此之外，Pinpoint 还实时检测请求是否成功，并利用 Failure 字段对请求的成功和失败进行标记。 最后汇总 Trace Log 可获得下表所示的 Trace 数据。\n   个人评论： 论文发表于 2002 年的 CCF B 类会议 DSN，是我看到的第一篇生成唯一的 Request ID，并进行全链路传播的论文，为以后 Trace 的实现提供了思路。但在传统的三层架构的服务架构下，Span 之间的父子关系是比较简单的，论文还未考虑复杂的 Parent-Child Span 的构建。\n 论文链接：https://ieeexplore.ieee.org/document/1029005\n  02 07_NSDI_X-Trace: A Pervasive Network Tracing Framework    论文简介: 现代 Internet 系统通常结合不同的应用程序，并且跨越不同的网络管理域。为了构建在分布式集群的网络链路，X-Trace 论文延续并扩展了 Pinpoint 论文的思路，提出了能够重新构建完整 Trace 的框架。\nX-Trace 的调用链追踪方案是对 Poinpont 思路的扩展，它将 Trace 的 Meta Data 写入到 message 中 (例如，写入到 HTTP 请求的拓展头上)，并沿着请求传播到经过的每个设备上。 与 Poinpont 相比，如下图所示 X-Trace 的 Meta Data 扩展了更多的元素，引入了 Span ID 和 Colletor 地址的概念。\n   此外，X-Trace 还设计了一个Trace Collector 的框架，将 Trace 的生成与采集解耦。X-Trace 在本地启动一个开放一个 UDP 协议端口的守护进程，应用可以将 Trace 发送到守护进程，并放入到一个队列中，队列的另外一边则将 Trace 发送到缓存或者持久化的数据库中。\n   个人评论： X-Trace 发表于 2007 年的 CCF A 类会议 NSDI，论文对 Trace 的 Meta Data 的定义已经初具雏形，Trace Collector 的架构也深深地影响了现今的 Opentelemetry Collector, Jeager Agent 等 Trace Collector。但 X-Trace 还主要注重于 Trace 结构的构建，对时间的开销是忽视的，不能很好地诊断性能问题。\n 论文链接：https://www.usenix.org/conference/nsdi-07/x-trace-pervasive-network-tracing-framework\n  03 10_Google_Dapper, a Large-Scale Distributed Systems Tracing Infrastructure    论文简介: Google 网站一个 Web Search 请求可能需要上千台服务器和很多不同开发团队开发的服务去处理，为了帮助理解系统的表现和论证效率，Google 设计和开发了 Dapper 用于观测整个系统的行为。 Dapper 的设计理念与 Pinpoint、 X-Trace 有许多是相通的，Dapper 更注重于在工业应用中的低开销和应用的透明化。\n由于 Google 内部的程序间的通信大多是通过 RPC 完成的，因此 Google 将 Dapper Trace 的预先插桩在 RPC 的框架内，预先定义所有 RPC 调用相关 Span，降低了 Trace 插桩的成本。下图展示了 Dapper Trace 的结构，Trace 由基本单元 Span 组成，一条 Trace 的所有 Span 共享唯一的可标识的 TraceID , 一个 Span 就是带有起止时间戳、RPC 耗时以及应用相关的 annotation。Parent Span 和 Child Span 通过 Parent ID 关联。引入 RPC 耗时将极大提升 Trace 用于根因定位潜力。\n   个人评论： 此外，为了达到低开销的设计目标，Dapper 还提出对 Trace 的采集进行采样。根据 Dapper 在谷歌的实践经验，对于许多常用的场景，即使对 1/1024 的请求进行采样收集，也能够得到足够的信息。\n 论文链接：https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf\n 在 Dapper 的论文发表之后，分布式链路系统日趋走向成熟，中间有一段百家争鸣的日子，Jaeger, Zipkin, OpenTracing, OpenCensus, Skywalking 等开源分布式链路系统都非常活跃。 随着2019年 Opentracing 和 Opencencus 的团队合并到 Opentelemtry 并加入 CNCF，Opentelemetry 的 OTEL 标准逐渐成为云原生 Trace 链路的主流并得到广泛使用。未来 Trace 还会如何进化，让我们保持期待！\nCloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1667692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667692800,"objectID":"b0ab6bfa52524e0363a372a6dd5b27d3","permalink":"https://yuxiaoba.github.io/post/trace_based_rca_1/","publishdate":"2022-11-06T00:00:00Z","relpermalink":"/post/trace_based_rca_1/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Trace 追踪了请求在应用程序中运行的轨迹，能够完整的串联起请求的上下文关系，在大规模分布式系统根因定位中的作用举足轻重 。在讨论 Trace 的根因定位之前，本文先介绍 Trace 的出现及其演进的过程。","tags":["Root Cause Analysis","Trace"],"title":"基于 Trace 的根因定位（一）： Trace 的演进之路","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"之前我总结了两种常见的基于 Metric 的根因定位算法 基于 Metrics 的根因定位 (一)：故障刻画 和 基于 Metrics 的根因定位 (二)：因果关系图 。这一次介绍第三种基于 Metric 的根因定位算法: 多维下钻。\n在 SRE 检测到 KPI 发生异常时（如响应成功率下降），还面临一个灵魂拷问：为什么发生异常了？（成功率为什么下降了？），这个时候我们需要增加维的层次，从而可以由粗粒度的数据到细粒度的数据来观察数据。\n例如下表我们发现某服务的当前总的失败请求数目比前一个时间点增加了很多，工程师会进一步挖掘失败请求的属性，比如查看数据中心的元素，发现广州的数据中心存在异常导致的这次故障，这就是一个简单的多维下钻的样例。\n   数据中心 前一时间点失败请求数 当前时间失败请求数 差异     广州 10 1000 990   上海 5 5    北京 10 11 1   合计 25 1016 991     01 14_NSDI_Adtributor: Revenue Debugging in Advertising Systems    论文简介: 论文针对广告营收领域的 revenue debugging问题，将多维根因分析问题分解为多个单维根因分析问题，提出了的 Adtributor 算法，并分别针对量值与率值两类指标进行多维度的根因分析。整体思路如下：\n  利用 ARMA 模型进行异常检测。根据8周的历史数据，考虑到正常的时间和星期的波动，生成一个基于模型的测量值预测。然后，将实际值与预测值进行比较：当一个测量值的实际值与预测值有明显差异时，将产生一个异常警报。\n  计算每个维度下每个元素的 explanatory power （单个元素预测值与实际值的差异和整个维度预测值与实际值差异的比值，论文公式 4） 与 surprise 值（可直观理解为预测值与实际值变化的程度，论文公式 5），定位出每个维度下的异常元素集合，最后根据每个维度总的 surprise 值大小汇总输出根因集合。\n     个人评论： Microsoft 2014 年发表在 NSDI （CCF A）上的论文，论文可以说是基于 Metrics 的多维下钻分析的开山之作，论文在 Mcirosoft 实际落地，可解释性比较强，后面的多维下钻的工作也大多在其基础之上进行创新。\n 论文链接：https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-bhagwan.pdf\n  02 16_ICSE_iDice: Problem Identification for Emerging Issues    论文简介: 软件在发布时一般会有很多分类属性（例如版本号，地域，操作平台等），如果发布有异常，用户通过会上报一些反馈的 Issue，此时需要运维工程师能够快速定位究竟是哪些属性造成了 Issue 的上升，提升响应的速度。文章以 Issue 的上升作为告警，通过分析一个时间窗口内 Issue 的属性的组合，找出最有可能导致 Issue 上升的最小属性组合。在搜索空间过大的问题上论文使用了启发式的三个剪枝策略来应对：\n  Impact based Pruning：一个有用的属性必须引起较大数量变化\n  Change Detection based Pruning: 一个有用的属性组合必须在时间点上符合变化特征\n  Isolation Power based Prunning: 合并多余属性组合\n     个人评论： MSRA 林庆维研究员 2016 年发表在 ICSE（CCF A）的论文。论文针对性地处理了用户反馈 Issue 的维度下钻，并在微软落地，剪枝的策略值得学习。\n 论文链接：http://hongyujohn.github.io/iDice.pdf\n  03 20_ASE_ImpAPTr: A Tool For Identifying The Clues To Online Service Anomalies    论文简介: 论文是一个广度优先的多维下钻根因定位算法，ImpAPTr，整体思路可分为以下四个步骤：\n  根据维度组合创建包含根结点和子结点的元素树，如下图所示；\n  采用广度优先遍历算法，删除冗余元素和影响系数 （Impact Factor）相反的元素（论文公式3）；\n  计算每个维度组合的贡献度 （Contribution Power，连续两个时间段的影响系数差值，论文公式4）和差异系数 （Diversity Factor， 两个连续时间段内的成功率指标变化程度， 论文公式 5） ；\n  计算每个维度组合 Contribution Power 和 Diversity Factor 的排名之和 ，选取前 n 个维度组合作为成功率下跌的根因线索。\n     个人评论： 论文是南京大学与美团合作发表在 ASE 2020 上的一篇短文。与 Adtributor 只考虑单个维度不同，ImpAPTr 考虑了多个维度，且构建出维度之间的关系图，通过在图上做广度优先搜索进行根因定位。美团实际落地算法的总结。方法在根因的属性数量不多以及单根因的时候效果应该会比较好。\n 论文链接：https://dl.acm.org/doi/10.1145/3324884.3415301\n代码链接：https://github.com/wanghaoUp/ImpAPTr\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1666310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666310400,"objectID":"253cb795c38ff29142d15d579a943536","permalink":"https://yuxiaoba.github.io/post/log_based_rca_1/","publishdate":"2022-10-21T00:00:00Z","relpermalink":"/post/log_based_rca_1/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Metrics 又是三者中在根因定位中最常用的数据源，阅读本文可快速了解当前学术界热门的基于 Metric 的根因定位算法类型——多维下钻。","tags":["Root Cause Analysis","Metrics"],"title":"基于 Logs 的根因定位 (三)：多维下钻","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"之前我总结了两种常见的基于 Metric 的根因定位算法 基于 Metrics 的根因定位 (一)：故障刻画 和 基于 Metrics 的根因定位 (二)：因果关系图 。这一次介绍第三种基于 Metric 的根因定位算法: 多维下钻。\n在 SRE 检测到 KPI 发生异常时（如响应成功率下降），还面临一个灵魂拷问：为什么发生异常了？（成功率为什么下降了？），这个时候我们需要增加维的层次，从而可以由粗粒度的数据到细粒度的数据来观察数据。\n例如下表我们发现某服务的当前总的失败请求数目比前一个时间点增加了很多，工程师会进一步挖掘失败请求的属性，比如查看数据中心的元素，发现广州的数据中心存在异常导致的这次故障，这就是一个简单的多维下钻的样例。\n   数据中心 前一时间点失败请求数 当前时间失败请求数 差异     广州 10 1000 990   上海 5 5    北京 10 11 1   合计 25 1016 991     01 14_NSDI_Adtributor: Revenue Debugging in Advertising Systems    论文简介: 论文针对广告营收领域的 revenue debugging问题，将多维根因分析问题分解为多个单维根因分析问题，提出了的 Adtributor 算法，并分别针对量值与率值两类指标进行多维度的根因分析。整体思路如下：\n  利用 ARMA 模型进行异常检测。根据8周的历史数据，考虑到正常的时间和星期的波动，生成一个基于模型的测量值预测。然后，将实际值与预测值进行比较：当一个测量值的实际值与预测值有明显差异时，将产生一个异常警报。\n  计算每个维度下每个元素的 explanatory power （单个元素预测值与实际值的差异和整个维度预测值与实际值差异的比值，论文公式 4） 与 surprise 值（可直观理解为预测值与实际值变化的程度，论文公式 5），定位出每个维度下的异常元素集合，最后根据每个维度总的 surprise 值大小汇总输出根因集合。\n     个人评论： Microsoft 2014 年发表在 NSDI （CCF A）上的论文，论文可以说是基于 Metrics 的多维下钻分析的开山之作，论文在 Mcirosoft 实际落地，可解释性比较强，后面的多维下钻的工作也大多在其基础之上进行创新。\n 论文链接：https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-bhagwan.pdf\n  02 16_ICSE_iDice: Problem Identification for Emerging Issues    论文简介: 软件在发布时一般会有很多分类属性（例如版本号，地域，操作平台等），如果发布有异常，用户通过会上报一些反馈的 Issue，此时需要运维工程师能够快速定位究竟是哪些属性造成了 Issue 的上升，提升响应的速度。文章以 Issue 的上升作为告警，通过分析一个时间窗口内 Issue 的属性的组合，找出最有可能导致 Issue 上升的最小属性组合。在搜索空间过大的问题上论文使用了启发式的三个剪枝策略来应对：\n  Impact based Pruning：一个有用的属性必须引起较大数量变化\n  Change Detection based Pruning: 一个有用的属性组合必须在时间点上符合变化特征\n  Isolation Power based Prunning: 合并多余属性组合\n     个人评论： MSRA 林庆维研究员 2016 年发表在 ICSE（CCF A）的论文。论文针对性地处理了用户反馈 Issue 的维度下钻，并在微软落地，剪枝的策略值得学习。\n 论文链接：http://hongyujohn.github.io/iDice.pdf\n  03 20_ASE_ImpAPTr: A Tool For Identifying The Clues To Online Service Anomalies    论文简介: 论文是一个广度优先的多维下钻根因定位算法，ImpAPTr，整体思路可分为以下四个步骤：\n  根据维度组合创建包含根结点和子结点的元素树，如下图所示；\n  采用广度优先遍历算法，删除冗余元素和影响系数 （Impact Factor）相反的元素（论文公式3）；\n  计算每个维度组合的贡献度 （Contribution Power，连续两个时间段的影响系数差值，论文公式4）和差异系数 （Diversity Factor， 两个连续时间段内的成功率指标变化程度， 论文公式 5） ；\n  计算每个维度组合 Contribution Power 和 Diversity Factor 的排名之和 ，选取前 n 个维度组合作为成功率下跌的根因线索。\n     个人评论： 论文是南京大学与美团合作发表在 ASE 2020 上的一篇短文。与 Adtributor 只考虑单个维度不同，ImpAPTr 考虑了多个维度，且构建出维度之间的关系图，通过在图上做广度优先搜索进行根因定位。美团实际落地算法的总结。方法在根因的属性数量不多以及单根因的时候效果应该会比较好。\n 论文链接：https://dl.acm.org/doi/10.1145/3324884.3415301\n代码链接：https://github.com/wanghaoUp/ImpAPTr\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1666310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666310400,"objectID":"c1f7da9e6acf38c00c7e81585e6f389e","permalink":"https://yuxiaoba.github.io/post/metric_based_rca_3/","publishdate":"2022-10-21T00:00:00Z","relpermalink":"/post/metric_based_rca_3/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Metrics 又是三者中在根因定位中最常用的数据源，阅读本文可快速了解当前学术界热门的基于 Metric 的根因定位算法类型——多维下钻。","tags":["Root Cause Analysis","Metrics"],"title":"基于 Metrics 的根因定位 (三)：多维下钻","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"微服务架构和CI/CD的出现让现代应用快速和频繁的开发和发布新的特性成为可能，但是频繁的代码和配置变更为系统引入了更多的不稳定因素。根据 Google SRE 书的描述有 70% 的 incident 都是由变更导致的，因此在程序灰度变更时及时的发现异常变更，尽快地采取 rollback 的策略是非常重要的。本文介绍三个学术界和工业界前沿的异常变更识别方法。\n 01 21_FSE_Identifying Bad Software Changes via Multimodal Anomaly Detection for Online Service Systems    论文简介: 随着微服务架构和 CICD 的普遍应用以及业务的压力，现代应用的变更越来越频繁。频繁的变更可以带来业务的快速迭代，但也增大了系统发生故障的概率。这篇论文首先对一个银行系统的历史故障进行了分析，然后得出 50 % 的故障是由于变更导致的，并且不同的变更反应在不同的 Metric 和 Log 上。因此作者提出将 Log 时序化，并通过融合Metric 和 Log 训练一个 LSTM 模型用于异常检测，如果LSTM模型预测值与实际值相差较大则会进行告警。\n   个人评论： 清华大学裴丹老师团队和天津大学陈俊洁老师合作的论文，论文发表在 CCF A 类会议 FSE 2021 上，论文从结构和语言上都非常值得学习。但是不是很能够理解变更系统引入日志，因为很有可能程序员在变更的时候就会打印新的日志，那这样也会被认定为程序出现了新的日志从而产生告警。\n 论文链接：https://netman.aiops.org/wp-content/uploads/2021/09/SCWarn.pdf\n代码链接：https://github.com/FSEwork/SCWarn\n  02 15_CoNEXT_Rapid and Robust Impact Assessment of Software Changes in Large Internet-based Services    论文简介: 当服务更新后，论文首先获得已更新服务实例、changed 服务以及 affected 服务的 KPI，然后基于一个改进版的 Singular Spectrum Transform 检测出异常的 KPI 。如果changed 服务发生性能变化，则基于 difference-in-difference (DiD) 检测属于changed 服务的已更新的服务实例（tinstance）和未更新服务实例（cinstance）的KPI 是否存在差异，如果存在差异可以直观的理解为更新导致他们的差异。如果是上游的 affected 服务的 KPI 发生变化，那则将服务更新前的 KPI 视为（cservice）和更新后的 KPI 视为（tservice），然后同样基于 DiD 检测他们是否有显著性的差异，如果存在差异则认为 affected 服务的变化是由于下游服务更新导致的。\n   个人评论： 论文是南开大学张圣林老师在读博士时在百度的工作，发表在 CCF B 类会议 CoNEXT 2015 上，论文只判断单个变更是否异常，如果上下游都有变更，很难进行处理。\n 论文链接：https://conferences2.sigcomm.org/co-next/2015/img/papers/conext15-final2.pdf\n  03 20_NSDI_Gandalf: An Intelligent, End-To-End Analytics Service for Safe Deployment in Large-Scale Cloud Infrastructure    论文简介: 当程序变更后，论文先统计失败的日志事件出现的次数，然后基于 Holt-Winters forecasting 检测出现异常的日志事件并判定为 Error。 对每一个 Error ，Gandalf 会计算它与变更的时空相关性。时间相关性基于假设“对一个变更，如果一个故障发生时间与变更的时间越接近，他们更相关”。空间相关性基于假设“在变更期间，未变更节点中发生的故障百分比越高，变更和故障之间的因果关系越低”。最后对于每个变更的得分，Gandalf 通过 Gaussian discriminant classifier 判断是否要继续变更还是 rollback。\n   个人评论： Gandalf 是 MicroSoft Azure 发表在 CCF A 类会议 NSDI 的论文，应该是有实际落地在用的。论文在投票阶段的描述应该是写错了，导致很难理解投票与反对的关系，建议可以看一下他的 presentation 来帮助理解。\n 论文链接：https://www.usenix.org/conference/nsdi20/presentation/li\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1664496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664496000,"objectID":"ec5af6fd6c137c1cdb3b8f7919f27d88","permalink":"https://yuxiaoba.github.io/post/change_1/","publishdate":"2022-09-30T00:00:00Z","relpermalink":"/post/change_1/","section":"post","summary":"微服务架构和CI/CD的出现让现代应用快速和频繁的开发和发布新的特性成为可能，但是频繁的代码和配置变更为系统引入了更多的不稳定因素。根据 Google SRE 书的描述有 70% 的 incident 都是由变更导致的，因此在程序灰度变更时及时的发现异常变更，尽快地采取 rollback 的策略是非常重要的。本文介绍三个学术界和工业界前沿的异常变更识别方法。","tags":["Change","Anomaly Detetion","AIOps"],"title":"异常变更识别(一)","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"实验室最近在 ASE2022，ISSRE2022, ICSOC2022, ICWS2022 等会议上，都有斩获，下面简单的分享一下我们的工作。\n 01 22_ASE_Graph based Incident Extraction and Diagnosis in Large-Scale Online Systems    论文简介: 在大规模微服务系统中，一个可用性的故障可能会因级联效应导致多个上游服务发生异常，这导致难以定位出真正的根因。为了解决这个问题，本文首先将 KPI 与前一天的 KPI 值进行对比对 KPI 进行异常检测，并基于 DBSCAN 和链路图抽取出与被故障影响的异常子图。接着将异常子图及其节点的特征输入到图神经网络中判断是否异常。如果异常，则在此异常子图上利用 Pagerank 定位出根因。\n   个人评论： 论文发表在 CCF A 类会议 ASE 2022 上，论文比较详细地介绍了当前微信内部基于指标和服务依赖图的根因定位算法，久经考验，非常值得落地学习。\n 论文链接：https://yuxiaoba.github.io/publication/gied22/gied22.pdf\n代码链接：https://github.com/IntelligentDDS/GIED\n  02 22_ISSRE_Going through the Life Cycle of Faults in Clouds:Guidelines on Fault Handling    论文简介: 即便是当前最先进的云平台，小范围的可用性故障依旧是层出不穷。云厂商在故障发生后，通常会公开自己对故障的事后分析来给用户一个解释。在本文中，我们收集并格式化了 354 个来自 AWS，Azure，Google 公开的故障的事后调查（incident）。在此数据集之上，我们从故障的生命周期：故障发生，故障检测，故障定位，故障修复四个方面对这些 incident 进行了定量和定性的研究，并获得了 10 个重要的发现。最后我们还基于这些发现指导当前云计算平台的智能运维，混沌工程和可观测性的研究。\n   个人评论： 论文发表在 CCF B 类会议 ISSRE 2022 上，采集这 300 多个 incident 的经历真的不堪回首，甚至还为我在微信实习的第一个工作打下了基础。在 rebuttal 的时候还出了突发情况，还好最后被录用了，不用再继续更新数据集了。当时我在读 Google SRE 书的时候突然想引用了几个名人名言，还挺有意思的。\n 论文链接：https://yuxiaoba.github.io/publication/incident22/incident22.pdf\n代码链接：https://github.com/IntelligentDDS/Post-mortems-Analysis\n  03 22_ICSOC_MicroSketch: Lightweight and Adaptive Sketch based Performance Issue Detection and Localization in Microservice Systems    论文简介: Trace 是可观测性的重要组成部分，但是基于 Trace 的异常检测和根因定位算法一直受制于对每条 Trace 分析带来的巨大开销。本文借鉴了网络通信中常用的 Sketch 的思想，首先基于 Sketch 计算出每个调用对的百分位数延迟，然后所有调用对的延迟输入到随机砍伐森林 (Robust Random Cut Forest) 中检测出异常的调用对，最后根据投票机制定位出根因。\n   个人评论： 论文发表在 CCF B 类会议 ICSOC 2022 上，考虑到大规模的生产系统上遍历分析每一条 Trace 的成本，把 Trace 指标化是当前工业界利用 Trace 进行分析的主要方式。本文提出了基于 Sketch 的轻量级 Trace 指标化方案，与遍历每条 Trace 进行分析的 Microrank 相比，速度提升明显。\n 论文链接：https://yuxiaoba.github.io/publication/microsketch22/microsketch22.pdf\n  04 22_ICWS_TS-InvarNet: Anomaly Detection and Localization based on Tempo-spatial KPI Invariants in Distributed Services    论文简介: 在大规模的分布式系统正常运行中，某两个 KPI 之间可能存在某种稳定的关系。例如，上下游服务因流量的一致性可能 CPU 利用率的变化存在相似的变化关系。我们把这种稳定的关系称为不变量。本文致力于在系统正常运行阶段挖掘出不同 KPI 之间的不变量关系，在系统发生故障后通过检测不变量是否被破坏来进行异常检测和根因定位。\n   个人评论: 当前的基于深度学习的异常检测算法通常可解释性比较差，我们提出的基于时空不变量的方法有较强的可解释性，易于工程师理解系统的变化。下图中展示了当故障发生时，不同节点的 KPI 之间不变量的变化的例子，非常容易理解。\n    论文链接：https://yuxiaoba.github.io/publication/tsinvarnet22/tsInvarNet22.pdf\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1662681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662681600,"objectID":"79afb2f80e204ebccf350cf6715788ca","permalink":"https://yuxiaoba.github.io/post/recent_paper1/","publishdate":"2022-09-09T00:00:00Z","relpermalink":"/post/recent_paper1/","section":"post","summary":"我们实验室最近在 ASE2022，ISSRE2022, ICSOC2022, ICWS2022 等会议上都有斩获，本文绝对是全网第一手消息。下面简单的介绍一下我们的工作，有兴趣的同学可以下载预览版的论文详细看看。","tags":["Root Cause Analysis","Anomaly Detetion","AIOps"],"title":"DDS 第一手消息（一）","type":"post"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"上篇文章基于 Metrics 的根因定位 (一)：故障刻画 介绍了使用故障刻画思想定位根因的几种算法。除故障刻画外，还有另外一种根因定位的思想是通过 Metrics 之间的依赖关系构建出因果关系图，然后基于相关性或随机游走算法在图上游走从而定位出根因。下面简要介绍典型的几个 Micro.X 算法。\n 01 18_ICSOC_Microscope: Pinpoint the Abnormal Services with Causal Graphs in Micro-service Environments    论文简介: 在不进行源代码进行插桩的情况下，Microscope 通过拦截网络连接信息和指标之间的相关性构建出微服务之间的因果关系图。在根因定位被触发时，Microscope 从前端对因果关系图进行遍历，找到因果关系图每个分支中最深的 SLO 异常服务并判定为根因候选。最后计算根因候选与前端服务的相关性为每个根因候选赋予得分。\n   个人评论： 论文是我导师来了中大以后组内的第一篇论文,发布在 CCF B 类会议 ICSOC 上。第一作者的师兄去了外交部，现在在非洲为国奋斗。论文的主要贡献放在因果关系图的构建，根因的推断是比较简单的深度优先搜索和根节点的相关性计算。\n 论文链接：https://link.springer.com/chapter/10.1007/978-3-030-03596-9_1\n  02 20_MicroRCA: Root Cause Localization of Performance Issues in Microservices    论文简介: MicroRCA 首先构建一个包含服务调用路径对应主机的属性图。在异常发生时，MicroRCA 通过判断服务之间的边的响应延迟是否异常提取异常子图。然后通过对子图进行加权计算连接节点之间的相似度，接着使用异常服务节点的响应时间与其容器资源利用率之间的最大相关系数来调整服务异常的分数，最后使用 PageRank 算法进行定位根因。\n   个人评论： 论文通过构建因果关系图，然后通过对图上的节点和边赋予权重进行 PageRank 计算，是一个通用的根因定位思路。\n 论文链接：https://hal.inria.fr/hal-02441640/document\n代码链接：https://github.com/elastisys/MicroRCA\n  03 21_MicroDiag: Fine-grained Performance Diagnosis for Microservice Systems    论文简介: MicroDiag 首先构建不同指标类型之间的异常传播依赖关系：\n 对资源类指标（如 CPU）传播, MicroDiag 采用 SCM（Structural Causal Model）推断异常的传播方向 对业务指标传播（如 Latency）MicroDiag 先用 Istio 获得服务依赖图，然后根据服务依赖图的逆向推断传播方向 通过资源类和业务类指标传播, MicroDiag 采用 Granger causality tests 推断异常的传播方向  接着 MicroDiag 通过皮尔逊相关系数计算指标间的相似性来判断异常传播的概率，在归一化权重后通过 PageRank 直接计算图中节点的重要性给出节点排序。\n   个人评论： 论文发表在 ICSE 2021 的 Workshop 上，对不同种类的资源采用不同的因果推断异常传播的方向值得学习。\n 论文链接：https://hal.inria.fr/hal-03155797/document\n  04 21_MicroHECL: High-Efﬁcient Root Cause Localization in Large-Scale Microservice Systems    论文简介: MicroHECL 首先根据根据最近30分钟的服务调用关系构造出服务依赖图，然后通过划分三个异常类型，构建出异常的传播图，最后根据异常传播图找到最深的节点作为根因\n 对性能故障，MicroHECL 采用 OC-SVM（one class support vector machine）以响应延迟的特征作为输入，判断是否存在性能故障。如果存在性能故障，故障传播从下游传播到上游 对可靠性故障，MicroHECL 采用随机森林以请求错误率的特征作为输入，判断是否存在可靠性故障。如果存在可靠性故障，故障传播从下游传播到上游 流量异常故障，MicroHECL 采用3-sigma 规则检测 QPS 的波动，判断是否存在流量异常故障。如果存在流量异常故障，故障传播从上游传播到下游  最后论文还提出了一个异常传播图剪枝的策略提高分析效率\n   个人评论： 本文是复旦大学彭鑫老师团队与阿里巴巴合作的论文，论文发表在 ICSE 2021 的 Workshop 上，论文预先对不同种类的异常进行分类，然后根据不同的传播方向分别构造异常传播图的思路值得学习。论文在阿里巴巴的数据上上取得 top3 为 68% 的准确率。\n 论文链接：https://arxiv.org/pdf/2103.01782.pdf\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1662249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662249600,"objectID":"151c586f57beaef6df96e85ea1d2369c","permalink":"https://yuxiaoba.github.io/post/metric_based_rca_2/","publishdate":"2022-09-04T00:00:00Z","relpermalink":"/post/metric_based_rca_2/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Metrics 又是三者中在根因定位中最常用的数据源，阅读本文可快速了解当前学术界热门的基于 Metric 的根因定位算法类型——因果关系图","tags":["Root Cause Analysis","Metrics"],"title":"基于 Metrics 的根因定位 (二)：因果关系图","type":"post"},{"authors":["Yufeng Li","Guangba Yu","Pengfei Chen","Chuanfu Zhang"],"categories":null,"content":"The blow figure shows the framework of MicroSketch.   ","date":1662163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662163200,"objectID":"6cc353f9a79bd0397be9e6da490176b3","permalink":"https://yuxiaoba.github.io/publication/microsketch22/","publishdate":"2022-09-03T00:00:00Z","relpermalink":"/publication/microsketch22/","section":"publication","summary":"In this study, we propose a lightweight and adaptive trace-based anomaly detection and RCA approach, named MicroSketch, which leverages Sketch based features and Robust Random Cut Forest (RRCForest) to rendertrace analysis more effective and efficient.","tags":["Cloud","Trace","RCA","AIOps"],"title":"MicroSketch: Lightweight and Adaptive Sketch based Performance Issue Detection and Localization in Microservice Systems","type":"publication"},{"authors":["Guangba Yu"],"categories":["Weekly Paper"],"content":"故障刻画是指通过提取历史的故障发生时不同 Metric 变化的特征，挖掘出不同种类故障发生时 Metric 变化的特征集合。在运行时阶段，可通过匹配特征集合定位到具体的故障种类。\n例如：CPU 竞争的故障的指标变化特征是 {“CPU 利用率升高”, “响应延迟升高”}。那么当在线程序出现 {“CPU 利用率升高”, “响应延迟升高”} 的情况时可推断为 CPU 竞争的故障。\n 01 22_FSE_Actionable and Interpretable Fault Localization for Recurring Failures in Online Service System    论文简介: Dejavu 是一种通过对故障进行刻画找到每种故障对应的特征，从而在故障重复发生时快速进行根因定位的方法。Dejavu 利用基于 gated recurrent unit (GRU) recurrent neural networks 构建的特征提取器统一表达故障故障单元（failure class）。然后根据 Trace 和 CMDB 构建的 failure dependency graph（FDG）。接着基于 graph attention networks (GAT) 算法对 FDG 图上的每个故障单元计算聚合的特征。最后在基于 dense neural network 为每个故障单元计算出故障的得分，得分最高的为根因故障。此外，Dejavu 还提供了故障的可解释算法用于向 SRE 解释故障的根因。\n   个人评论： 论文是清华大学裴丹老师团队在 CCF A类会议 FSE 上发表。论文主要针对故障重复发生的场景，需要大量的标签，且无法很好地处理新的故障。\n 论文链接：https://arxiv.org/abs/2207.09021 代码链接：https://github.com/NetManAIOps/DejaVu\n  02 20_VLDB_Diagnosing Root Causes of Intermittent Slow Queries in Cloud Databases    论文简介: MicroRCA 首先构建一个包含服务调用路径对应主机的属性图。在异常发生时，MicroRCA 通过判断服务之间的边的响应延迟是否异常提取异常子图。然后通过对子图进行加权计算连接节点之间的相似度，接着使用异常服务节点的响应时间与其容器资源利用率之间的最大相关系数来调整服务异常的分数，最后使用 PageRank 算法进行定位根因。\n   论文定义了四种值得参考的异常类型\n   个人评论： MSRA 马明华博士在阿里巴巴李飞飞博士团队访问时发表在 CCF A类会议 VLDB 上的论文。文章是一篇优秀的故障刻画文章。创新性的提出利用指标的类型来增加更多的线索，方法也可以用于指标的压缩。但是要获得 Level Shift Up 的类型需要长时间的数据采集，不能实现及时的根因定位。\n 论文链接：http://www.vldb.org/pvldb/vol13/p1176-ma.pdf\n代码链接：https://github.com/NetManAIOps/DejaVu/blob/master/iSQUAD/iSQ.py\n  03 21_ISSRE_Identifying Root-Cause Metrics for Incident Diagnosis in Online Service Systems    论文简介: 论文从大规模的生产系统中总结出 13 种典型的异常模式。然后提出了一个有监督的根因定位算法 PatternMatcher. PatternMatcher采用双样本假设检验作为粗粒度的异常检测算法，筛选出在该事件发生时表现正常的指标，从而大大减少搜索空间。之后，利用主动学习对历史故障进行标签，训练出一种基于一维CNN的异常模式分类方法，过滤掉那些工程师不关心的异常模式。最后利用 p-value 方法对每个指标计算得分并排序。\n   论文中总结的典型的指标异常模式：\n   个人评论： 论文是清华大学裴丹老师团队的论文，论文总结出的典型的指标异常模式是很值得学习的。\n 论文链接：http://netman.aiops.org/wp-content/uploads/2021/10/wch_ISSRE-1.pdf\n CloudWeekly 每周分享与云计算相关论文，相关的论文集被收纳到 github 仓库 https://github.com/IntelligentDDS/awesome-papers\n","date":1662163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662163200,"objectID":"0a08da9caa67e3b5599ab03050e85b51","permalink":"https://yuxiaoba.github.io/post/metric_based_rca_1/","publishdate":"2022-09-03T00:00:00Z","relpermalink":"/post/metric_based_rca_1/","section":"post","summary":"Metrics, Traces, Logs 被誉为可观测性的三大支柱。Metrics 又是三者中在根因定位中最常用的数据源，阅读本文可快速了解当前学术界热门的基于 Metric 的根因定位算法类型——故障刻画","tags":["Root Cause Analysis","Metrics"],"title":"基于 Metrics 的根因定位 (一)：故障刻画","type":"post"},{"authors":["Xiaoyun Li","Guangba Yu","Pengfei Chen","Hongyang Chen","Zhekang Chen"],"categories":null,"content":"The blow figure shows the fault type of cloud incident.   ","date":1658188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188800,"objectID":"c5634e31791011a62a49b29aba4b9b37","permalink":"https://yuxiaoba.github.io/publication/incident22/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/publication/incident22/","section":"publication","summary":"When cloud service experience failures, it is typical to conduct a \"post-mortem\" analysis after its recovery to understand what went wrong, what went right, and how the team could do better in the future. When those failures are public-facing, it is common for some portion of those post-mortem analyses to be made publicly available. The paper describes an analysis of 354 publicly visible post-mortem analyses for three popular three popular large-scale clouds. Based on these findings, the authors have suggested some guidelines on fault handling using chaos engineering, observability, and intelligent operations considerations.","tags":["Cloud","Incident","Reliability","AIOps"],"title":"Going through the Life Cycle of Faults in Clouds:Guidelines on Fault Handling","type":"publication"},{"authors":["Zilong He","Pengfei Chen","Yu Luo","Qiuyu Yan","Hongyang Chen","Guangba Yu","Fangyuan Li"],"categories":null,"content":"The blow figure shows the framework of GIED.   ","date":1658188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658188800,"objectID":"e87f791f20e4efcf3f6791a154ec907f","permalink":"https://yuxiaoba.github.io/publication/gied22/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/publication/gied22/","section":"publication","summary":"This paper proposes a novel system, named GIED, which is a method to automatically analyze the cascading effect of availability issues in online systems. GIED enables the extraction of graph-based issue representations. This representation includes both the issue symptoms and affected service attributes. A neural network is used to perform incident detection. Finally, the PageRank algorithm is used to locate the root cause of the incident.","tags":["Microservice","RCA","PageRank","Reliability","AIOps"],"title":"Graph based Incident Extraction and Diagnosis in Large-Scale Online Systems","type":"publication"},{"authors":["Zijun Hu","Pengfei Chen","Guangba Yu","Zilong He","Xiaoyun Li"],"categories":null,"content":"The evolution of an invariant network when a failure occurred.   ","date":1652572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652572800,"objectID":"eae9bb9c6c34f6a3e9b1d66a42674db6","permalink":"https://yuxiaoba.github.io/publication/tsinvarnet22/","publishdate":"2022-05-15T00:00:00Z","relpermalink":"/publication/tsinvarnet22/","section":"publication","summary":"In this paper, we design and implement TS-InvarNet, an interpretable end-to-end anomaly detection and diagnosis framework based on tempo-spatial KPI invariants.","tags":["Microservice","Anomaly Detection"],"title":"TS-InvarNet: Anomaly Detection and Localization based on Tempo-spatial KPI Invariants in Distributed Services","type":"publication"},{"authors":["Xiaoyun Li","Pengfei Chen","Linxiao Jing","Zilong He","Guangba Yu"],"categories":null,"content":"The blow figure shows the framework of SwissLog.   ","date":1646956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646956800,"objectID":"633bb2e683b7209387add7bfdca44ab7","permalink":"https://yuxiaoba.github.io/publication/swisslog22/","publishdate":"2022-03-29T00:00:00Z","relpermalink":"/publication/swisslog22/","section":"publication","summary":"In this paper, we propose SwissLog, namely a robust and unified deep learning based anomaly detection model for detecting diverse faults based on logs.","tags":["Anomaly Detection","Reliability","AIOps"],"title":"SwissLog: Robust Anomaly Detection andLocalization for Interleaved Unstructured Logs","type":"publication"},{"authors":null,"categories":null,"content":"MicroRank is a novel system to locate root causes that lead to latency issues in microservice environments.\nMicroRank extracts service latency from tracing data then conducts the anomaly detection procedure.\nBy combining PageRank and spectrum analysis, the service instances that lead to latency issues are ranked with high scores.\n   ","date":1643760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643760000,"objectID":"e38c5ff30b55d39e048a22f440a44bab","permalink":"https://yuxiaoba.github.io/project/microrank/","publishdate":"2022-02-02T00:00:00Z","relpermalink":"/project/microrank/","section":"project","summary":"MicroRank is a novel system to locate root causes that lead to latency issues in microservice environments..","tags":["RCA"],"title":"MicroRank","type":"project"},{"authors":null,"categories":null,"content":"Online Boutique is a cloud-native microservices demo application. Online Boutique consists of a 10-tier microservices application. The application is a web-based e-commerce app where users can browse items, add them to the cart, and purchase them. Google uses this application to demonstrate use of technologies like Kubernetes, Istio, Stackdriver, gRPC. This application works on any Kubernetes cluster (such as a local one). It’s easy to deploy with little to no configuration.\nWe instrument OpenTelemetry API for each service to equip tracing ability for Online Boutique.\n   ","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"445d1e1e2aedcae075dd0b097fa1068e","permalink":"https://yuxiaoba.github.io/project/hipster/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/project/hipster/","section":"project","summary":"An microservice benchmark equipped with Opentelemetry.","tags":["Telemetry"],"title":"Opentelemetry Microservice Benchmark","type":"project"},{"authors":["Guangba Yu","Zicheng Huang","Pengfei Chen"],"categories":null,"content":"The blow figure shows the framework of TraceRank.   ","date":1638835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638835200,"objectID":"db2d54f5e5c4f2e00ebb6b09b79615ee","permalink":"https://yuxiaoba.github.io/publication/tracerank/","publishdate":"2022-01-30T00:00:00Z","relpermalink":"/publication/tracerank/","section":"publication","summary":"This paper proposes a novel system named TraceRank to identify and locate abnormal services causing performance problems with dis-aggregated end-to-end traces.","tags":["Microservice","RCA","Spectrum","Reliability","AIOps"],"title":"TraceRank: Abnormal Service Localization with Dis-Aggregated End-to-End Tracing Data in Cloud Native Systems","type":"publication"},{"authors":["Zicheng Huang","Pengfei Chen","Guangba Yu","Hongyang Chen","Zibin Zheng"],"categories":null,"content":"","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636934400,"objectID":"d49081e990754a5f624913e968a06cc2","permalink":"https://yuxiaoba.github.io/publication/sieve21/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/sieve21/","section":"publication","summary":"In this paper, we design and implement Sieve, an online sampler that aims to bias sampling towards uncommon traces by taking advantage of the attention mechanism.","tags":["Microservice","Trace Sample"],"title":"Sieve: Attention-based Sampling of End-to-End Trace Data in Distributed Microservice Systems","type":"publication"},{"authors":["Zihao Ye","Pengfei Chen","Guangba Yu"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"acdd6de933d9c344852cfa8000e4b20b","permalink":"https://yuxiaoba.github.io/publication/trank/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/trank/","section":"publication","summary":"This paper proposes a novel system, named T-Rank, which analyzes clues provided by normal and abnormal traces to locate root causes of latency issues.","tags":["Microservice","RCA","Spectrum","Reliability","AIOps"],"title":"T-Rank:A Lightweight Spectrum based Fault Localization Approach for Microservice Systems","type":"publication"},{"authors":["Tianjun Weng","Wanqi Yang","Guangba Yu","Pengfei Chen","Jieqi Cui","Chuangfu Zhang"],"categories":null,"content":"","date":1622246400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622246400,"objectID":"65cf8358e41abd3a456589f8b11e7e67","permalink":"https://yuxiaoba.github.io/publication/kmon/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/kmon/","section":"publication","summary":"This paper proposes a novel system, named Kmon, which is an In-kernel transparent monitoring system for microservice systems with extended Berkeley Packet Filter (eBPF).","tags":["Microservice","Telemetry","eBPF","AIOps"],"title":"Kmon: An In-kernel Transparent Monitoring System for Microservice Systems with eBPF","type":"publication"},{"authors":["Guangba Yu","Pengfei Chen","Hongyang Chen","Zijie Guan","Zicheng Huang","Linxiao Jing","Tianjun Weng","Xinmeng Sun","Xiaoyun Li"],"categories":null,"content":"The blow figure shows the framework of MicroRank.   ","date":1618790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618790400,"objectID":"cafae48bc398bb049eec5d795d76836b","permalink":"https://yuxiaoba.github.io/publication/microrank/","publishdate":"2022-01-30T00:00:00Z","relpermalink":"/publication/microrank/","section":"publication","summary":"This paper proposes a novel system, named MicroRank, which analyzes clues provided by normal and abnormal traces to locate root causes of latency issues.","tags":["Microservice","RCA","Spectrum","Reliability","AIOps"],"title":"MicroRank: End-to-End Latency Issue Localization with Extended Spectrum Analysis in Microservice Environments","type":"publication"},{"authors":["Jieqi Cui","Pengfei Chen","Guangba Yu"],"categories":null,"content":"","date":1606867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606867200,"objectID":"3b672b07c060dae67db36fea8f939f99","permalink":"https://yuxiaoba.github.io/publication/icpads20/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/icpads20/","section":"publication","summary":"This paper presents a learning-based approach to route requests in order to balance the load in the multi-cloud environment .","tags":["Microservice","Perfromance","Load balance"],"title":"A Learning-based Dynamic Load Balancing Approach for Microservice Systems in Multi-cloud Environment","type":"publication"},{"authors":["Xiaoyun Li","Pengfei Chen","Linxiao Jing","Zilong He","Guangba Yu"],"categories":null,"content":"The blow figure shows the framework of SwissLog.   ","date":1605052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605052800,"objectID":"ee53ee78635dda99dacd54554abb2d6a","permalink":"https://yuxiaoba.github.io/publication/swisslog20/","publishdate":"2022-01-31T00:00:00Z","relpermalink":"/publication/swisslog20/","section":"publication","summary":"In this paper, we propose SwissLog, namely a robust and unified deep learning based anomaly detection model for detecting diverse faults based on logs.","tags":["Anomaly Detection","Reliability","AIOps"],"title":"SwissLog: Robust and Unified Deep Learning Based Log Anomaly Detection for Diverse Faults","type":"publication"},{"authors":["Zilong He","Pengfei Chen","Xiaoyun Li","Yongfeng Wang","Guangba Yu","Cailin Chen","Xinrui Li","Zibin Zheng"],"categories":null,"content":"The blow figure shows the framework of Topomad.   ","date":1602806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602806400,"objectID":"9d28915585314db5e03d4c6d71bc33c3","permalink":"https://yuxiaoba.github.io/publication/topomad20/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/topomad20/","section":"publication","summary":"In this article, we propose TopoMAD, a stochastic seq2seq model which can robustly model spatial and temporal dependence among contaminated data.","tags":["Anomaly Detection","Reliability","AIOps"],"title":"A Spatiotemporal Deep Learning Approach for Unsupervised Anomaly Detection in Cloud Systems","type":"publication"},{"authors":["Guangba Yu","Pengfei Chen","Zibin Zheng"],"categories":null,"content":"The blow figure shows the framework of Microscaler.   ","date":1586131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586131200,"objectID":"d519808ab893a6f3148da042bd00ea8e","permalink":"https://yuxiaoba.github.io/publication/microscaler20/","publishdate":"2022-01-31T00:00:00Z","relpermalink":"/publication/microscaler20/","section":"publication","summary":"In this paper, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the Service Level Agreement (SLA) with an optimal cost for microservice applications.","tags":["Microservice","Resource","Perfromance","Autoscale","AIOps"],"title":"Microscaler: Cost-effective Scaling for Microservice Applications in the Cloud with an Online Learning Approach","type":"publication"},{"authors":["Hongyang Chen","Pengfei Chen","Guangba Yu"],"categories":null,"content":"","date":1584835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584835200,"objectID":"efd6529cd1fd88c5434b62f2ce074893","permalink":"https://yuxiaoba.github.io/publication/vwr20/","publishdate":"2022-01-31T00:00:00Z","relpermalink":"/publication/vwr20/","section":"publication","summary":"In this paper, we build a system named “VWR”, a framework of Virtual War Room for operating microservice applications which allows users to simulate their microservice architectures with low overhead and inject multiple types of faults into the microservice system with chaos engineering.","tags":["Microservice","Chaos Engineering","Fault Injection","Anomaly Detection"],"title":"A Framework of Virtual War Room and Matrix Sketch-Based Streaming Anomaly Detection for Microservice Systems","type":"publication"},{"authors":["Guangba Yu","Pengfei Chen","Zibin Zheng"],"categories":null,"content":"The blow figure shows the framework of Microscaler.   ","date":1567036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567036800,"objectID":"632d29de87ff94606b866ec378d11cb3","permalink":"https://yuxiaoba.github.io/publication/microscaler19/","publishdate":"2022-01-31T00:00:00Z","relpermalink":"/publication/microscaler19/","section":"publication","summary":"In this paper, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the service level agreement (SLA) with an optimal cost for micro-service systems.","tags":["Microservice","Resource","Perfromance","Autoscale","AIOps"],"title":"Microscaler: Automatic Scaling for Microservices with an Online Learning Approach","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}   Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://yuxiaoba.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"\r[23/01/24] Root Cause Change Analysis Framework ChangeRCA and Trace Sampling Framework TraStrainer are accepted by FSE 2024.\n[28/07/23] Multi-modal Observability Data RCA Framework Nezha and Configuration Optimization Framework Diagconfig are accepted by FSE 2023.\n[16/06/23] Automatic Power Management Framwork DeepPower and Automatic Network Root Cause Analysis Framework MARS are accepted by ICPP 2023.\n[06/05/23] Delivering FaaS Function to Computing Continuum FrameworkFaaSDeliver is accepted by Transaction on Service Computing.\n[16/12/22] Log Reduce Framework LogReducer is accepted by ICSE 2023.\n[06/05/22] Guangba is awarded Tencent Rhino-Bird Research Elite Program and Tencent Special Scholarship in 2022.\n","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"https://yuxiaoba.github.io/news/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/news/","section":"","summary":"List of news.\r\n","tags":[],"title":"News","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://yuxiaoba.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]